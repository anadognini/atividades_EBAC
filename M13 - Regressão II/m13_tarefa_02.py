# -*- coding: utf-8 -*-
"""m13_tarefa_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFAEDw6DGMBsfpUI7L6NJrLgtj-YH4fj

# EBAC - Regressão II - Módulo 13 - Tarefa I

#### Previsão de renda II

Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.

|variavel|descrição|
|-|-|
|data_ref                | Data de referência de coleta das variáveis |
|index                   | Código de identificação do cliente|
|sexo                    | Sexo do cliente|
|posse_de_veiculo        | Indica se o cliente possui veículo|
|posse_de_imovel         | Indica se o cliente possui imóvel|
|qtd_filhos              | Quantidade de filhos do cliente|
|tipo_renda              | Tipo de renda do cliente|
|educacao                | Grau de instrução do cliente|
|estado_civil            | Estado civil do cliente|
|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|
|idade                   | Idade do cliente|
|tempo_emprego           | Tempo no emprego atual|
|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|
|renda                   | Renda em reais|

### **Início**
"""

pip install -U scikit-learn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import r2_score
from sklearn.impute import SimpleImputer
import statsmodels.api as sm
from sklearn.tree import DecisionTreeRegressor
import patsy

# Carregando o DataFrame

df = pd.read_csv('previsao_de_renda.csv')

# Definindo colunas numéricas e categóricas usadas nas análises

num_cols = ['idade', 'tempo_emprego', 'qtd_filhos', 'qt_pessoas_residencia']
cat_cols = ['sexo','posse_de_veiculo','posse_de_imovel','tipo_renda','educacao','estado_civil','tipo_residencia']

# Imputação: mediana para numéricas, moda para categóricas

df_clean = df.copy()

num_imputer = SimpleImputer(strategy='median')
df_clean[num_cols] = num_imputer.fit_transform(df_clean[num_cols])

for c in cat_cols:
    if c in df_clean.columns:
        df_clean[c] = df_clean[c].fillna(df_clean[c].mode().iloc[0])

# Criando X (dummies) e y a partir do mesmo df_clean

X = pd.get_dummies(df_clean.drop(columns=['renda','id_cliente','data_ref'], errors='ignore'), drop_first=True)
y = df_clean['renda']

"""### **1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Resetando índices

X_train = X_train.reset_index(drop=True)
X_test  = X_test.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)
y_test  = y_test.reset_index(drop=True)

X_train = num_imputer.fit_transform(X_train)
X_test = num_imputer.transform(X_test)

"""### **2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?**"""

alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]

ridge_results = {}

for a in alphas:
    ridge = Ridge(alpha=a)
    ridge.fit(X_train, y_train)
    y_pred = ridge.predict(X_test)
    ridge_results[a] = r2_score(y_test, y_pred)

ridge_results

"""### **3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?**"""

lasso_results = {}

for a in alphas:
    lasso = Lasso(alpha=a, max_iter=10000)
    lasso.fit(X_train, y_train)
    y_pred = lasso.predict(X_test)
    lasso_results[a] = r2_score(y_test, y_pred)

lasso_results

"""Apesar de o Ridge apresentar estabilidade e pouca variação, o melhor desempenho foi obtido com o modelo Lasso com alpha = 0.1, que produziu o maior R² na base de teste.
A diferença é pequena, mas o Lasso mostrou um ajuste levemente superior neste conjunto de dados.

### **4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?**
"""

X_train_df = pd.DataFrame(X_train, columns=X.columns)
X_test_df = pd.DataFrame(X_test, columns=X.columns)

def stepwise_selection(X, y,
                       initial_list=[],
                       threshold_in=0.05,
                       threshold_out=0.05,
                       verbose=True):
    included = list(initial_list)

    while True:
        changed = False
        excluded = list(set(X.columns) - set(included))
        new_pval = pd.Series(index=excluded, dtype=np.float64)

        for new_column in excluded:
            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()
            new_pval[new_column] = model.pvalues[new_column]
        best_pval = new_pval.min()

        if best_pval < threshold_in:
            best_feature = new_pval.idxmin()
            included.append(best_feature)
            changed = True

            if verbose:
                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))

        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()
        pvalues = model.pvalues.iloc[1:]
        worst_pval = pvalues.max()  # null if pvalues is empty

        if worst_pval > threshold_out:
            worst_feature = pvalues.idxmax()
            included.remove(worst_feature)
            changed = True

            if verbose:
                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))

        if not changed:
            break

    return included

selected_features = stepwise_selection(X_train_df, y_train, verbose=True)
print("Selected features:", selected_features)

X_train_sel = sm.add_constant(X_train_df[selected_features])
X_test_sel  = sm.add_constant(X_test_df[selected_features])
model_step = sm.OLS(y_train, X_train_sel).fit()

y_pred_test_step = model_step.predict(X_test_sel)
r2_step = r2_score(y_test, y_pred_test_step)
print("R^2 stepwise (test):", r2_step)

"""### **5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?**

O stepwise generaliza bem, porém não supera o Ridge, nem o Lasso. Como é um modelo menor e mais simples, ele ainda assim pode ser útil.

- Ridge: melhor R² ≈ 0.269015;
- Lasso: melhor R² ≈ 0.2690216;
- Stepwise: R² ≈ 0.267868.

O melhor modelo ainda é o Lasso (alpha = 0.1). O Ridge vem logo em seguida. A diferença é muito pequena, mas sistematicamente menor.

### **6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.**

#### Modelo A
"""

train_df, test_df = train_test_split(df_clean, test_size=0.25, random_state=42)
train_df = train_df.reset_index(drop=True)
test_df  = test_df.reset_index(drop=True)

formula_A = """
np.log(renda) ~
C(sexo)
+ C(tipo_renda)
+ C(educacao)
+ C(estado_civil)
+ C(posse_de_veiculo)
+ C(posse_de_imovel)
+ C(tipo_residencia)
+ np.log(tempo_emprego + 1)
+ np.power(tempo_emprego, 2)
+ idade
+ np.power(idade, 2)
+ C(sexo)*idade
+ C(sexo)*tempo_emprego
+ C(tipo_renda)*tempo_emprego
"""

yA, XA = patsy.dmatrices(formula_A, train_df, return_type="dataframe")
XA_test = patsy.build_design_matrices([XA.design_info], test_df)[0]

modelA = sm.OLS(yA, XA).fit()
predA = modelA.predict(XA_test).reshape(-1)
y_test_log = np.log(test_df['renda']).values

r2_patsy_A = r2_score(y_test_log, predA)
print("R^2 patsy Model A (test):", r2_patsy_A)

"""### **7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela.**"""

depths = [2, 3, 4, 5, 7, 10, 15, None]

tree_results = {}

for d in depths:
    tree = DecisionTreeRegressor(max_depth=d, random_state=42)
    tree.fit(X_train, y_train)
    y_pred = tree.predict(X_test)
    tree_results[d] = r2_score(y_test, y_pred)

tree_results

best_depth = max(tree_results, key=tree_results.get)
best_r2 = tree_results[best_depth]

print(f"Melhor profundidade: {best_depth}")
print(f"Melhor R² no teste: {best_r2:.5f}")

"""Em comparação com Ridge, Lasso, Stepwise e o modelo A, a Árvore de Regressão conseguiu obter o melhor R² ≈ 0.381. Porém, a diferença não é tão grande. Além disso, dificilmente a Árvore de Regressão vai superar muito, porque renda é difícil de prever e árvores sofrem com ruído e variáveis categóricas dumificadas. Modelos lineares co interação (como o modelo A) ainda são melhores, por conseguirem captar melhor a estrutura."""