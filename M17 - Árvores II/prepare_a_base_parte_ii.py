# -*- coding: utf-8 -*-
"""prepare_a_base_parte_ii.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qaWKkCWA7QcGJQqnSOJWYP77y-ESCICx
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

pg1 = pd.read_csv('pg1.csv')
pg1.head()

print(pg1.isna().sum())
print('Quantidade de linhas:', pg1.shape[0])
print('Quantidade de colunas:', pg1.shape[1])

# Estamos retirando 'species' das variáveis explicativas, porque ela é o alvo
X = pd.get_dummies(pg1.drop(columns=['species', 'island']), drop_first=True)
y = pg1['species']

X_train, X_test, y_train, y_test = train_test_split(X, y)

y_train.value_counts()

"""### A árvore"""

clf = DecisionTreeClassifier(random_state=2360873, max_depth=3)
clf.fit(X_train, y_train)

import graphviz
from sklearn.tree import export_graphviz

dot_data = export_graphviz(clf, out_file=None,
                           feature_names=X_train.columns,
                           class_names=['Adelie', 'Chinstrap', 'Gentoo'],
                           filled=True)
graph = graphviz.Source(dot_data, format='png')
graph

"""### Pós-poda"""

caminho = DecisionTreeClassifier(random_state=2360873, max_depth=3).cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = caminho.ccp_alphas, caminho.impurities

clfs = []

for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=ccp_alpha).fit(X_train, y_train)
    clfs.append(clf)

train_scores = [clf.score(X_train, y_train) for clf in clfs]
test_scores = [clf.score(X_test, y_test) for clf in clfs]

fig, ax = plt.subplots()
ax.set_xlabel('Alpha')
ax.set_ylabel('Accuracy')
ax.set_title('Acurácia X Alpha do conjunto de treino e teste')
ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')
ax.plot(ccp_alphas, test_scores, marker='o', label='test', drawstyle='steps-post')
ax.legend()
plt.show()

# Selecionando a melhor árvore
ind_melhor_arvore = len(test_scores) - test_scores[::-1].index(max(test_scores)) - 1
melhor_arvore = clfs[ind_melhor_arvore]
melhor_arvore

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_pred = melhor_arvore.predict(X_test)
matrix = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))
matrix.plot()