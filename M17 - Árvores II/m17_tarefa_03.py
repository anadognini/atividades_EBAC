# -*- coding: utf-8 -*-
"""Profissão Cientista de Dados M17 - Pratique 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x67gCKVrRLNlEc37Z741ZmB-nzTcPdMc

# Árvores II - Tarefa 3

### 1. Carregar as bases

Vamos utilizar nesta tarefa as bases de reconhecimento de atividade humana através do celular. Carregue novamente as bases salvas na tarefa I.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV

X_train = pd.read_csv('/content/X_train.csv', index_col=0)
X_test  = pd.read_csv('/content/X_test.csv', index_col=0)
y_train = pd.read_csv('/content/y_train.txt', header=None, names=['activity_label'])
y_test  = pd.read_csv('/content/y_test.txt', header=None, names=['activity_label'])

"""### 2. Calcule os ```ccp_alphas```.

Vamos seguir uma lógica bem em linha com o que já estamso acostumados, com as seguintes orientações:

- Utilizar treinamento e teste conforme já vieram definidos originalmente
- Por pragmatismo, utilizar ```min_samples_leaf=20```
- Utilize as mesmas "3 melhores variáveis" identificadas no exercício anterior.
"""

# Alinhando os rótulos aos índices das bases

y_train = y_train.loc[X_train.index]
y_test  = y_test.loc[X_test.index]

X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42)

# Selecionando as 3 melhores variáveis

top_features = [
    'angle(X,gravityMean)',
    'fBodyAccJerk-bandsEnergy()-1,8',
    'tGravityAcc-arCoeff()-Y,1'
]

X_train_3 = X_train_split[top_features]
X_valid_3 = X_valid[top_features]

clf_base = DecisionTreeClassifier(min_samples_leaf=20, random_state=42)
clf_base.fit(X_train_3, y_train_split)
caminho = clf_base.cost_complexity_pruning_path(X_train_3, y_train_split)
ccp_alphas = caminho.ccp_alphas

ccp_alphas = ccp_alphas[::5]

clfs = []

for alpha in ccp_alphas:
    clf = DecisionTreeClassifier(min_samples_leaf=20, ccp_alpha=alpha, random_state=42)
    clf.fit(X_train_3, y_train_split)
    clfs.append(clf)

train_scores = [clf.score(X_train_3, y_train_split) for clf in clfs]
valid_scores = [clf.score(X_valid_3, y_valid) for clf in clfs]

fig, ax = plt.subplots(figsize=(8, 5))

ax.set_xlabel('ccp_alpha')
ax.set_ylabel('Acurácia')
ax.set_title('Acurácia vs ccp_alpha')
ax.plot(ccp_alphas, train_scores, marker='o', label='Treino', drawstyle='steps-post')
ax.plot(ccp_alphas, valid_scores, marker='o', label='Validação', drawstyle='steps-post')
ax.legend()
plt.show()

ind_melhor = np.argmax(valid_scores)
melhor_alpha = ccp_alphas[ind_melhor]

print(f'Melhor alpha: {melhor_alpha:.2f}')

# Treinando o modelo final

X_train_full_3 = X_train[top_features]

clf_final = DecisionTreeClassifier(min_samples_leaf=20, ccp_alpha=melhor_alpha, random_state=42)
clf_final.fit(X_train_full_3, y_train)

X_test_3 = X_test[top_features]
acuracia_teste = clf_final.score(X_test_3, y_test)

print(f'Acurácia no teste: {acuracia_teste * 100:.2f}%')

# Matriz de confusão

y_pred = clf_final.predict(X_test_3)
disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))

disp.plot()
plt.show()

"""### 3. *Grid Search*

Vou deixar especificações iniciais mínimas, que visam limitar o tempo de máquina, pois um procedimento desses pode demorar muito tempo dependendo da especificação. Mas conforme você for ficando confortável com o tempo consumido pelo procedimento, pode fazer um algoritmo mais exaustivo, por exemplo, avaliando mais valores de ```ccp_alpha```.

- Meça o tempo
- Utilize a base de treinamento
- Utilize um *cross validation* do tipo *k-fold*, especifique k=10
- Você pode ler 1 a cada ```k``` valores para uma melhor varredura utilizando, por exemplo, ```ccp_alpha[::10]```
- Não se esqueça de limitar o número de variáveis
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# param_grid = {'ccp_alpha': ccp_alphas[::10]}
# 
# clf_cv = DecisionTreeClassifier(min_samples_leaf=20, random_state=42)
# grid = GridSearchCV(estimator=clf_cv, param_grid=param_grid, cv=10)
# grid.fit(X_train_3, y_train_split)

"""### 4. Avaliando a árvore

- Obtenha a árvore na melhor configuração treinada em toda a base de treino
- Calcule a acurácia dessa árvore na base de testes
- Visualize a matriz de confusão
"""

resultados = pd.DataFrame(grid.cv_results_)
resultados.head()

melhor_ccp = resultados.iloc[grid.best_index_, 4]
print(f'Melhor ccp_alpha: {melhor_ccp}')

X_train_full_3 = X_train[top_features]

clf_final = DecisionTreeClassifier(min_samples_leaf=20, ccp_alpha=melhor_ccp, random_state=2360873)
clf_final.fit(X_train_full_3, y_train)

X_test_3 = X_test[top_features]

acuracia_teste = clf_final.score(X_test_3, y_test)
print(f'Acurácia no teste: {acuracia_teste * 100:.2f}%')

y_pred = clf_final.predict(X_test_3)

matriz = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))
matriz.plot()
plt.show()

"""### 5. Melhorando a árvore

A melhor forma de se melhorar um algoritmo é colocando nele novas variáveis que agreguem valor. Podemos usar a força-bruta e ir colocando variáveis aleatoriamente - ou colocar todas e deixar rodando por um bom tempo - ou utilizar uma lógica eficiente e fazer uma seleção de variáveis.

- Observe que há classes mais fáceis e mais difíceis de se identificar
- Crie uma variável binária para uma das classes de maior erro
- Fala uma árvore de classificação bem simples para esta variável:
    - utilize ```mean_samples_leaf=20```
    - utilize ```max_depth=4```
    - coloque todas as variáveis
- Observe a importância das variáveis, e selecione as 3 com maior importância
- Rode novamente o algoritmo acima com as 3 novas variáveis e avalie a acurácia

Identificar uma classe difícil → transformá-la em um problema binário → entender quais variáveis são mais importantes para distinguir essa classe → usar essas variáveis para melhorar o modelo original.

Isso é uma técnica clássica chamada, informalmente, de: one-vs-rest orientado por erro.

Usar o erro do modelo para guiar a engenharia de variáveis.
"""

# Passo 1 - Identificar a classe com maior erro

# Matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Erro por classe (1 − recall)

erros = 1 - np.diag(cm) / cm.sum(axis=1)
classe_dificil = np.argmax(erros)

print(f'Classe mais difícil: {classe_dificil}')

# Passo 2 - Criar a variável binária

y_train_bin = (y_train['activity_label'] == classe_dificil).astype(int)
y_test_bin  = (y_test['activity_label'] == classe_dificil).astype(int)

# Passo 3 - Árvore simples (binária, todas as variáveis)

clf_bin = DecisionTreeClassifier(min_samples_leaf=20, max_depth=4, random_state=42)
clf_bin.fit(X_train, y_train_bin)

# Passo 4 - Importância das variáveis

importancias = pd.DataFrame({'feature': X_train.columns, 'importance': clf_bin.feature_importances_}).sort_values(by='importance', ascending=False)
importancias.head(10)

# Selecionando as 3 melhores

novas_top_features = importancias.head(3)['feature'].tolist()
print(novas_top_features)

# Passo 5 - Treinar novamente a árvore multiclasses com as novas variáveis

X_train_new = X_train[novas_top_features]
X_test_new  = X_test[novas_top_features]

clf_final_novo = DecisionTreeClassifier(min_samples_leaf=20, random_state=42)
clf_final_novo.fit(X_train_new, y_train)

# Avaliação final
acuracia_nova = clf_final_novo.score(X_test_new, y_test)
print(f'Acurácia com novas variáveis: {acuracia_nova * 100:.2f}%')

y_pred_new = clf_final_novo.predict(X_test_new)

disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_new))
disp.plot()
plt.show()

