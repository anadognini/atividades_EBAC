# -*- coding: utf-8 -*-
"""m17_tarefa_02ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l_ZgLppXdg1944fq-3dociGSPhzXv6NN

# Árvores II - Tarefa 2

### 1. Carregar as bases

Vamos carregar as bases lidas na tarefa passada. Se você salvou essas bases em arquivo texto, basta fazer a leitura com o comando ```pd.read_csv``` das seguintes bases:

- X_train
- Y_train
- X_test
- Y_test

Não se esqueça de considerar a leitura dos índices dos arquivos no ```read_csv()```!
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

X_train = pd.read_csv('/content/X_train.csv', index_col=0)
X_test  = pd.read_csv('/content/X_test.csv', index_col=0)
y_train = pd.read_csv('/content/y_train.txt', header=None, names=['activity_label'])
y_test  = pd.read_csv('/content/y_test.txt', header=None, names=['activity_label'])

"""### 2. Divisão da base em Treino, Validação e Teste

A base já se encontra dividida em Treino e Validação. O que vamos fazer então é extrair uma base de Validação da base de Treino.

Extraia 25% da base de treino como base de validação.
"""

X_train_split, X_valid, y_train_split, y_valid = train_test_split(
    X_train,
    y_train.loc[X_train.index],
    test_size=0.25,
    random_state=42
)

"""### 3. Melhores 3 variáveis

Rode uma árvore com profundidade máxima igual a 4 para prever a atividade humana com todas as variáveis.
Observe a importância das variáveis e considere as 3 variáveis com maior importância para os próximos passos.
Dica: utilize o atributo ```clf.feature_importances_``` da árvore treinada.
"""

clf = DecisionTreeClassifier(max_depth=4)
clf.fit(X_train_split, y_train_split)

importances = clf.feature_importances_
features = X_train_split.columns
feature_importances = pd.DataFrame({'feature': features, 'importance': importances})
feature_importances.sort_values(by='importance', ascending=False, inplace=True)
feature_importances.head(3)

"""### 4. Construa uma árvore com as 3 melhores variáveis

Utilizando as três variáveis encontradas acima, construa uma árvore de decisão. Encontre o melhor ```ccp_alpha``` utilizando a base de validação, conforme a estrutura que vimos em aula.
"""

top_features = [
    'angle(X,gravityMean)',
    'fBodyAccJerk-bandsEnergy()-1,8',
    'tGravityAcc-arCoeff()-Y,1'
]

X_train_3 = X_train_split[top_features]
X_valid_3 = X_valid[top_features]

clf_3 = DecisionTreeClassifier(random_state=42)
clf_3.fit(X_train_3, y_train_split)

caminho = DecisionTreeClassifier(random_state=2360873, max_depth=3).cost_complexity_pruning_path(X_train_3, y_train_split)
ccp_alphas, impurities = caminho.ccp_alphas, caminho.impurities

clfs = []

for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=ccp_alpha, max_depth=3).fit(X_train_3, y_train_split)
    clfs.append(clf)

train_scores = [clf.score(X_train_3, y_train_split) for clf in clfs]
valid_scores = [clf.score(X_valid_3, y_valid) for clf in clfs]

fig, ax = plt.subplots()
ax.set_xlabel('Alpha')
ax.set_ylabel('Accuracy')
ax.set_title('Acurácia X Alpha do conjunto de treino e teste')
ax.plot(ccp_alphas, train_scores, marker='o', label='train', drawstyle='steps-post')
ax.plot(ccp_alphas, valid_scores, marker='o', label='test', drawstyle='steps-post')
ax.legend()
plt.show()

best_idx = np.argmax(valid_scores)
best_alpha = ccp_alphas[best_idx]
best_acc = valid_scores[best_idx]

print(f"Melhor ccp_alpha: {best_alpha}")
print(f"Acurácia na validação: {best_acc:.4f}")

"""### 5. Avaliação do modelo

Avalie a árvore encontrada no item anterior na base de testes.
"""

X_test_3 = X_test[top_features]

test_scores = [clf.score(X_test_3, y_test) for clf in clfs]

ind_melhor_arvore = np.argmax(valid_scores)
melhor_arvore = clfs[ind_melhor_arvore]

acuracia_teste = melhor_arvore.score(X_test_3, y_test)

print(f'Acurácia: {acuracia_teste * 100:.2f}')

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_pred = melhor_arvore.predict(X_test_3)
matrix = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))

matrix.plot()
plt.show()