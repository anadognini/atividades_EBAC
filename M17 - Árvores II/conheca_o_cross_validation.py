# -*- coding: utf-8 -*-
"""conheca_o_cross_validation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vkFxqU4BqCCZIENX7_jkZDPIdYsI6ghp

### Tentativa com uma base de testes holdout
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

pg1 = pd.read_csv('pg1.csv')
pg1.head()

X = pd.get_dummies(pg1.drop(columns=['species', 'island']), drop_first=True)
y = pg1.species

X_, X_test, y_, y_test = train_test_split(X, y, test_size=0.2, random_state=2360873) # Separando 20% para a base de teste
X_train, X_valid, y_train, y_valid = train_test_split(X_, y_, test_size=0.25, random_state=1729) # Usando train_test_split novamente em todo os 80% restantes

print(X_test.size) # 20%
print(X_valid.size) # 20%
print(X_train.size) # 60%

caminho = DecisionTreeClassifier(random_state=2360873).cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = caminho.ccp_alphas, caminho.impurities

ccp_alphas

clfs = []

for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=2360873, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    clfs.append(clf)

clfs

train_scores = [clf.score(X_train, y_train) for clf in clfs]
valid_scores = [clf.score(X_valid, y_valid) for clf in clfs]

fig, ax = plt.subplots()
ax.set_xlabel("Alpha")
ax.set_ylabel("Acurácia")
ax.set_title("Acurácia X Alpha do conjunto de dados de treino e validação")
ax.plot(ccp_alphas, train_scores, marker='o', label='Treino', drawstyle="steps-post")
ax.plot(ccp_alphas, valid_scores, marker='o', label='Validação', drawstyle="steps-post")
ax.legend()
plt.show()

ind_melhor_arvore = len(valid_scores) - valid_scores[::-1].index(max(valid_scores)) - 1
melhor_arvore = clfs[ind_melhor_arvore]

print(f'Acurácia da melhor árvore na base de validação: {valid_scores[ind_melhor_arvore] * 100:.2f}')
print(melhor_arvore)

"""### Avaliando a melhor árvore na base de testes"""

acuracia_teste = melhor_arvore.score(X_test, y_test)

print(f'Acurácia: {acuracia_teste * 100:.2f}')

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_pred = melhor_arvore.predict(X_test)
matrix = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))
matrix.plot()