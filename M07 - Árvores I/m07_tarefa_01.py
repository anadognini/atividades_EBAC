# -*- coding: utf-8 -*-
"""m07_tarefa_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13oh_LEpZHfEeQqYIbgTbZcZdP5rag2ge

# Módulo 07, Tarefa 01

Vamos começar a mexer na nossa base de projeto? Já fizemos um exercício de montar a variável resposta, já pudemos perceber que essa atividade pode não ser trivial. Vamos agora trabalhar a base para que fique propícia ao *scikitlearn* para trabalharmos.

Lembrando, a base se chama demo01.csv, e originalmente está publicada [aqui](https://www.kaggle.com/rikdifos/credit-card-approval-prediction).

#### 1) Carregue a base e avalie:

- As variáveis
- Tipos de dados de cada variável
- Quantidade de missings
- Distribuição da variável resposta (mau)
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# carregando o arquivo "demo01.csv" que contém a base de dados

credit = pd.read_csv('/kaggle/input/demo01/demo01.csv')
credit.head()

# Carregando as variáveis utilizando o atributo columns e transformando em lista para que fique mais fácil de
# visualizar

list(credit.columns)

# Carregando os tipos de dados de cada variável através do atributo dtypes

credit.dtypes

# Carergando a quantidade de missings utilizando o método isna() e aplicando o método sum() que somará todos os
# valores verdadeiros

credit.isna().sum()

# Carregando a distribuição da variável resposta (mau) através de value_counts() conta a quantidade de ocorrências
# para cada valor da variável

credit['mau'].value_counts()

"""#### 2) Vamos montar um metadados

1. Crie um dataframe com os nomes de cada variável e o tipo de dados de cada variável.
2. Adicione uma  nesse *dataframe* chamada "qtd_categorias" e coloque nela o número de categorias correspondente de cada variável.
    Dica:
        1. inicie uma lista vazia
        2. faça um for ao longo dos nomes das variáveis,
        3. conte o número de categorias dessa variável
        4. acumule essa informação de 3. na lista que você criou em 1.
        5. No final, essa lista pode ser atribuída à nossa variável.
3. Crie variáveis dummy para as variáveis necessárias (i.e. aquelas que são qualitativas e não estão armazenadas como {0, 1} ou {True, False}.
"""

# Crie um dataframe com os nomes de cada variável e o tipo de dados de cada variável

# Utilizando o método DataFrame do pandas para criar um dataframe, foi passado um dicionário
# com duas chaves, coluna (que indica o nome da coluna no dataframe original) e tipo (que exibe o tipo de dado
# daquela coluna). Bastou utilizar os atriutos columns e dtypes para criar as colunas do novo dataframe.
# O nome dado a esse dataframe foi "metadados".

metadados = pd.DataFrame({'nome': credit.columns, 'tipo': credit.dtypes})

metadados

# Adicione uma  nesse dataframe chamada "qtd_categorias" e coloque nela o número de categorias
# correspondente de cada variável.

# Iniciando uma lista vazia

qtd_categorias = []
nm_categorias = [] # Criei uma coluna extra para mostrar os valores de cada coluna

# Fazendo um um for ao longo dos nomes das variáveis

for col in metadados['nome']:
    qtd_variavel = credit[col].nunique() # Contando o número de categorias dessa variável utlizando o método nunique(),
                                         # que retorna o número de valores únicos, enquanto unique() retornar os
                                         # próprios valores únicos.
    qtd_categorias.append(qtd_variavel)  # Adicionando essa informação à lista que foi criada inicialmente.


    nomes = credit[col].unique() # Fiz o mesmo para a lista nm_categorias
    nm_categorias.append(nomes)

# No final, as listas podem ser atribuídas às nossa variáveis
metadados['qtd_categorias'] = qtd_categorias
metadados['nm_categorias'] = nm_categorias

metadados

"""Metadados refere-se a novos dados que explicam os dados originais. Nesse caso, criamos esse novo dataframe para explicar as colunas do nosos dataframe *credit*. Ele exibe as próprias colunas e seus nomes, o tipo de dado que elas possuem, a quantidade de valores/categorias e os próprios valores/categorias. Isso auxilia bastante na hora da análise.

Com base nisso, é possível perceber que temos algumas colunas cujo tipo de dado é object e que precisarão ser tratadas posteriormente. São elas:

* sexo = object [M, F]
* posse_de_veiculo = object [Y, N]
* posse_de_imovel = object [Y, N]
* tipo_renda = object [Working, Commercial associate, State servant,...
* educacao = object [Secondary / secondary special, Higher educati...
* estado_civil = object [Married, Single / not married, Civil marriage...
* tipo_residencia = object [House / apartment, Rented apartment, Municipa...

#### 3) Crie variáveis dummy para as variáveis necessárias (i.e. aquelas que são qualitativas e não estão armazenadas como {0, 1} ou {True, False}. Crie um *dataframe* apenas com as variáveis apropriadas para entrada no scikitlearn - elimine as variáveis tipo *str*, mantendo apenas suas versões *dummy*.
"""

# Criando variáveis dummy para as variáveis necessárias (i.e. aquelas que são qualitativas e não estão
# armazenadas como {0, 1} ou {True, False}.

# Tratando as variáveis:

# tipo_renda = object [Working, Commercial associate, State servant,...
# educacao = object [Secondary / secondary special, Higher educati...
# estado_civil = object [Married, Single / not married, Civil marriage...
# tipo_residencia = object [House / apartment, Rented apartment, Municipa...

# Para essas, optei por utilizar o método get_dummies, passando o parâmetro "drop_first=True", para evitar
# redundância de dados, pois essas variáveis possuem mais do que 2 valores, então não é possível transformá-las
# em uma única coluna com valores binários.

credit_encoded = pd.get_dummies(credit, columns=['tipo_renda', 'educacao', 'estado_civil',
                                                         'tipo_residencia'], drop_first=True, dtype=int)
credit_encoded.head(20)

# Tratando as colunas:

# sexo = object [M, F]
# posse_de_veiculo = object [Y, N]
# posse_de_imovel = object [Y, N]

# Como essas variáveis possuem apenas dois valores que se opõem, optei por utilizar um mapping e transformá-las
# em variáveis binárias.

credit_encoded.sexo = credit_encoded.sexo.map({'F': 1, 'M': 0})
credit_encoded.posse_de_veiculo = credit_encoded.posse_de_veiculo.map({'Y': 1, 'N': 0})
credit_encoded.posse_de_imovel = credit_encoded.posse_de_imovel.map({'Y': 1, 'N': 0})

# mau = bool [False, True]

# A variável "mau" (target) não é object mas também não é int. Optei por transformá-la em int para facilitar
# a análise.

credit_encoded.mau = credit_encoded.mau.astype(int)

credit_encoded.info()

"""#### 4) Qual variável é mais poderosa?

Considere as variáveis ```possui_email``` e ```posse_de_veiculo```. Faça uma tabela cruzada entre elas e responda qual delas te parece mais poderosa para prever a probabilidade de ```mau = 1```?
"""

# Criando uma tabela cruzada entre a variável "possui_email" e "posse_de_veiculo". O parâmetro "marings" exibe
# a somatória dos valores das colunas e linhas nas margens da tabela. O parâmetro "normalize" calcula a
# frequência dos valores.

pd.crosstab(credit_encoded['possui_email'], credit_encoded['posse_de_veiculo'], margins=True, normalize=True)

# Criando uma tabela cruzada comparando as duas variáveis explicativas com a variável target. Outro parâmetro
# adicionado foi o parâmetro aggfunc, que realiza o cálculo de uma função de agregação. Nesse caso,
# as entradas são a soma dos valores da coluna mau para cada combinação.

pd.crosstab(credit_encoded['possui_email'], credit_encoded['posse_de_veiculo'], credit_encoded['mau'], margins=True, normalize=True, aggfunc='sum')

"""Comparando os valores obtidos nas tabelas cruzadas, a variável "possui_email" parece ser mais poderosa em prever a variável target ("mau") porque a diferença nas taxas de mau pagador entre aqueles que possuem e não possuem email é maior do que a diferença entre aqueles que possuem ou não um veículo. Quando a pessoa possui email, a taxa de mau pagador é significativamente menor em comparação com aqueles que não possuem email, indicando uma relação mais forte entre "possui_email" e a capacidade de pagamento.

#### 5) Salve a base, pois ela será utilizada no final deste módulo.
"""

credit_encoded.to_csv('credit.csv')