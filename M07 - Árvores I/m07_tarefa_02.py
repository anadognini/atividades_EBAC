# -*- coding: utf-8 -*-
"""m07_tarefa_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iS-Og8ncU_oFgLwR0AZ91XbMGNd-wUWE

# Módulo 07 - Tarefa 02

#### 1) Carregue a base e garanta que a base está como deveria.

Considere a base que você ajustou na lição passada. Carregue-a. Caso ainda haja alguma pendência, ajuste - lembre-se de que o scikitlearn não recebe variáveis em formato string, somente numéricas, e não aceita '*missings*'.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.tree import DecisionTreeClassifier, plot_tree

renda = pd.read_csv('/content/demo01.csv')
renda.head()

# Verificando os tipos das variáveis

print(renda.dtypes)

# Verificando se há algum valor missing

renda.isna().sum()

renda['mau'] = renda['mau'].astype(int) # Garantindo que mau é numérico

renda_dummy = pd.get_dummies(renda, drop_first=True)

renda_dummy.head()

"""Separe 70% da base para treinamento e 30% para validação. Cada uma dessas partes terá dois objetos, um armazenando a variável resposta ```mau```e outro armazenando as variáveis explicativas (lembrando: sem variáveis string, já com as dummies)."""

# Separando variável resposta
y = renda_dummy['mau']

# Variáveis explicativas (todas exceto mau)
X = renda_dummy.drop('mau', axis=1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.30,
    random_state=42,
    stratify=y
)

X_train.shape, X_test.shape

"""#### 2) Vamos para o modelo:

1. Defina um objeto com a função da árvore de decisão vista em aula.
"""

clf = DecisionTreeClassifier(random_state=100)
clf = clf.fit(X_train, y_train)

"""2. Treine o modelo com os dados que você separou para treinamento."""

train_pred = clf.predict(X_train)
train_acc = accuracy_score(y_train, train_pred)

"""3. Visualize a árvore. Talvez você queira aumentar um pouco a figura."""

plt.figure(figsize=(20, 10))
plot_tree(
    clf,
    feature_names=X_train.columns,
    class_names=['aprovados', 'reprovados'],
    filled=True,
    rounded=True,
    fontsize=9
)

plt.title("Árvore de Decisão - modelo treinado")
plt.show()

"""4. Produza uma visualização da matriz de classificação (ou matriz de confusão) - coloque os rótulos como "aprovados" e "reprovados" - pois afinal de contas, são essas as decisões que se podem tomar com propostas de crédito."""

y_pred = clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6,5))
ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                 xticklabels=['aprovados','reprovados'],
                 yticklabels=['aprovados','reprovados'])

ax.set_xlabel("Predito")
ax.set_ylabel("Verdadeiro")
ax.set_title("Matriz de Confusão")
plt.show()

"""5. Calcule a acurácia na base de treinamento"""

print(f"Acurácia no treino: {train_acc:.4f}")

"""#### 3) Vamos avaliar o modelo na base de testes

1. Classifique a base de teste de acordo com a árvore que você treinou no item 2.

2. Produza a visualização da matriz de confusão para a base de teste.
"""

y_pred_test = clf.predict(X_test)

# Produzindo a matriz de confusão
cm_test = confusion_matrix(y_test, y_pred_test)

plt.figure(figsize=(6,5))
sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',
            xticklabels=['bons','maus'],
            yticklabels=['bons','maus'])
plt.xlabel("Predito")
plt.ylabel("Verdadeiro")
plt.title("Matriz de Confusão - Base de Teste")
plt.show()

"""3. Calcule a acurácia da base de teste. Compare com a acurácia da base de treinamento."""

test_acc = accuracy_score(y_test, y_pred_test)
print(f"Acurácia no teste: {test_acc:.4f}")

print(f"Acurácia no treino: {train_acc:.4f}")
print(f"Overfitting? {'Sim' if train_acc > test_acc else 'Não'}")

"""O overfitting se manifesta quando um algoritmo se adapta excessivamente ou até mesmo de forma precisa aos dados de treinamento, levando a um modelo que não consegue fazer previsões ou conclusões precisas com outros dados que não sejam os de treinamento.

No desenvolvimento de algoritmos de aprendizado de máquina, normalmente é usado um conjunto de dados de amostra para treinar o modelo. Entretanto, quando o modelo é treinado por um período prolongado nos dados de amostra ou quando o modelo é excessivamente complexo, ele pode começar a aprender o "ruído", ou seja, informações irrelevantes, dentro do conjunto de dados. Quando o modelo memoriza o ruído e se adapta excessivamente ao conjunto de treinamento, ele se torna "overfitted" e não consegue generalizar bem para novos dados. Se um modelo não puder generalizar bem para novos dados, ele não será capaz de executar as tarefas de classificação ou previsão para as quais foi destinado.

4. Treine uma nova árvore com número mínimo de observações por folha de 5 e máximo de profundidade de 10. Use o random_state = 123. Avalie a matriz de classificação. Observe a distribuição da predição - qual a proporção de proponentes foram classificados como 'maus'?
"""

clf2 = DecisionTreeClassifier(
    min_samples_leaf=5,
    max_depth=10,
    random_state=123
)

clf2.fit(X_train, y_train)
y_pred2 = clf2.predict(X_test)
cm2 = confusion_matrix(y_test, y_pred2)

plt.figure(figsize=(6,5))
sns.heatmap(cm2, annot=True, fmt='d', cmap='Greens',
            xticklabels=['bons','maus'],
            yticklabels=['bons','maus'])
plt.xlabel("Predito")
plt.ylabel("Verdadeiro")
plt.title("Matriz de Confusão - Árvore Ajustada (min_leaf=5, max_depth=10)")
plt.show()

acc2 = accuracy_score(y_test, y_pred2)
print(f"Acurácia da árvore ajustada: {acc2:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred2, target_names=['bons','maus']))

prop_maus_preditos = y_pred2.mean()
print(f"Proporção de proponentes classificados como 'maus': {prop_maus_preditos:.4f}")

"""5. Como ficaria a acurácia se você classificasse todos os contratos como 'bons'?"""

y_all_good = [0] * len(y_test)

acc_all_good = accuracy_score(y_test, y_all_good)
print(f"Acurácia classificando todos como bons: {acc_all_good:.4f}")

"""A base ficaria muito desbalanceada, com poucos maus pagadores."""