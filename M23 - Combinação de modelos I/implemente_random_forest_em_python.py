# -*- coding: utf-8 -*-
"""implemente_random_forest_em_python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15m3jd_-VItpK45PyXBke29nlQG-Dy0IF
"""

import patsy
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime
from scipy.stats import ks_2samp
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('credit_scoring.csv', parse_dates=['data_ref'])
df['tempo_emprego'].fillna(-1, inplace=True)
df.head()

# Selecionar meses de 2016 para validação
df_val = df[df['data_ref'] >= datetime(2016, 1, 1)].copy()

# Selecionar meses de 2015 para treinamento e e teste
df = df[df['data_ref'] <= datetime(2016, 1, 1)]

df_train, df_test = train_test_split(df, test_size=0.3, random_state=12)
df_train = df_train.reset_index(drop=True)
df_test = df_test.reset_index(drop=True)
df_val = df_val.reset_index(drop=True)

print(f'Quantidade de linhas no treino: {df_train.shape[0]}')
print(f'Quantidade de linhas no teste: {df_test.shape[0]}')
print(f'Quantidade de linhas na validação: {df_val.shape[0]}')

equacao = '''mau ~ sexo + posse_de_veiculo + posse_de_imovel + qtd_filhos +
         tipo_renda + educacao + estado_civil + tipo_residencia + idade +
          qt_pessoas_residencia'''

y_train, X_train = patsy.dmatrices(equacao, data=df_train)
y_test, X_test = patsy.dmatrices(equacao, data=df_test)
y_val, X_val = patsy.dmatrices(equacao, data=df_val)

def calcular_gini(resp, prob_default):
  # AUC
  auc = roc_auc_score(resp, prob_default)

  # Gini
  gini = 2 * auc - 1
  return gini

def print_metricas(dados, prob_default='PD', classe_predita='classe_predita', resp='mau'):
  # Acurácia
  acc = accuracy_score(dados[resp], dados[classe_predita])

  # AUC
  auc = roc_auc_score(dados[resp], dados[prob_default])

  # Gini
  gini = 2 * auc -1

  # KS
  ks = ks_2samp(dados.loc[dados[resp] == 1, prob_default],
                dados.loc[dados[resp] != 1, prob_default]).statistic

  print(f'Acurácia: {acc * 100:.2f}%')
  print(f'AUC: {auc * 100:.2f}%')
  print(f'Gini: {gini * 100:.2f}%')
  print(f'KS: {ks * 100:.2f}%')

  return None

clf = RandomForestClassifier(n_estimators=600, max_depth=13, min_samples_leaf=41)
clf.fit(X_train, y_train.ravel())
# n_estimators = quantidade de árvores treinadas

df_train['classe_predita'] = clf.predict(X_train) # Calculando se foi marcado como 0 ou 1
df_train['PD'] = clf.predict_proba(X_train)[:, 1] # Calculando a probabilidade

df_test['classe_predita'] = clf.predict(X_test)
df_test['PD'] = clf.predict_proba(X_test)[:, 1]

df_val['classe_predita'] = clf.predict(X_val)
df_val['PD'] = clf.predict_proba(X_val)[:, 1]

print_metricas(dados=df_train)
print_metricas(dados=df_test)
print_metricas(dados=df_val)