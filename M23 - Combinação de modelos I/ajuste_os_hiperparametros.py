# -*- coding: utf-8 -*-
"""ajuste_os_hiperparametros.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fye8S3JhH9AnZLQ0vaWjV_nF2KV296KS
"""

import patsy
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime
from scipy.stats import ks_2samp
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('credit_scoring.csv', parse_dates=['data_ref'])
df['tempo_emprego'].fillna(-1, inplace=True)
df.head()

# Selecionar meses de 2016 para validação
df_val = df[df['data_ref'] >= datetime(2016, 1, 1)].copy()

# Selecionar meses de 2015 para treinamento e e teste
df = df[df['data_ref'] <= datetime(2016, 1, 1)]

df_train, df_test = train_test_split(df, test_size=0.3, random_state=12)
df_train = df_train.reset_index(drop=True)
df_test = df_test.reset_index(drop=True)
df_val = df_val.reset_index(drop=True)

print(f'Quantidade de linhas no treino: {df_train.shape[0]}')
print(f'Quantidade de linhas no teste: {df_test.shape[0]}')
print(f'Quantidade de linhas na validação: {df_val.shape[0]}')

equacao = '''mau ~ sexo + posse_de_veiculo + posse_de_imovel + qtd_filhos +
         tipo_renda + educacao + estado_civil + tipo_residencia + idade +
          qt_pessoas_residencia'''

y_train, X_train = patsy.dmatrices(equacao, data=df_train)
y_test, X_test = patsy.dmatrices(equacao, data=df_test)
y_val, X_val = patsy.dmatrices(equacao, data=df_val)

def calcular_gini(resp, prob_default):
  # AUC
  auc = roc_auc_score(resp, prob_default)

  # Gini
  gini = 2 * auc - 1
  return gini

def print_metricas(dados, prob_default='PD', classe_predita='classe_predita', resp='mau'):
  # Acurácia
  acc = accuracy_score(dados[resp], dados[classe_predita])

  # AUC
  auc = roc_auc_score(dados[resp], dados[prob_default])

  # Gini
  gini = 2 * auc -1

  # KS
  ks = ks_2samp(dados.loc[dados[resp] == 1, prob_default],
                dados.loc[dados[resp] != 1, prob_default]).statistic

  print(f'Acurácia: {acc * 100:.2f}%')
  print(f'AUC: {auc * 100:.2f}%')
  print(f'Gini: {gini * 100:.2f}%')
  print(f'KS: {ks * 100:.2f}%')

  return None

clf = RandomForestClassifier(n_estimators=600, max_depth=13, min_samples_leaf=41)
clf.fit(X_train, y_train.ravel())
# n_estimators = quantidade de árvores treinadas

df_train['classe_predita'] = clf.predict(X_train) # Calculando se foi marcado como 0 ou 1
df_train['PD'] = clf.predict_proba(X_train)[:, 1] # Calculando a probabilidade

df_test['classe_predita'] = clf.predict(X_test)
df_test['PD'] = clf.predict_proba(X_test)[:, 1]

df_val['classe_predita'] = clf.predict(X_val)
df_val['PD'] = clf.predict_proba(X_val)[:, 1]

print_metricas(dados=df_train)
print_metricas(dados=df_test)
print_metricas(dados=df_val)

"""### Grid Search 1 - Variando o número de árvores"""

grid = list(range(100, 1001, 150))
grid

lista_gini_test=[]
lista_gini_train=[]

grid = list(range(100, 1001, 150))

for num_arvores in grid:
  clf = RandomForestClassifier(n_estimators=num_arvores,
                               max_depth=10,
                               min_samples_leaf=5)

  clf.fit(X_train, y_train.ravel())

  gini_test = calcular_gini(y_test, clf.predict_proba(X_test)[:, 1])
  gini_train = calcular_gini(y_train, clf.predict_proba(X_train)[:, 1])

  lista_gini_test.append(gini_test)
  lista_gini_train.append(gini_train)

lista_gini_test = []
lista_gini_train = []

grid = list(range(100, 1001, 150))

for num_arvores in grid:
  clf = RandomForestClassifier(n_estimators=num_arvores,
                               max_depth=10,
                               min_samples_leaf=5,
                               n_jobs=-1)

  clf.fit(X_train, y_train.ravel())

  gini_test = calcular_gini(y_test, clf.predict_proba(X_test)[:, 1])
  gini_train = calcular_gini(y_train, clf.predict_proba(X_train)[:, 1])

  lista_gini_test.append(gini_test)
  lista_gini_train.append(gini_train)

zip_gini_train = zip(list(range(100, 1001, 150)), lista_gini_train)
zip_gini_test = zip(list(range(100, 1001, 150)), lista_gini_test)

dict_gini_train = dict(zip_gini_train)
dict_gini_test = dict(zip_gini_test)
print(dict_gini_train)

series_gini_train = pd.Series(dict_gini_train)
series_gini_test = pd.Series(dict_gini_test)
print(series_gini_train)

fig, ax = plt.subplots()

ax.plot(series_gini_train, '-b', label="Treino")
ax.plot(series_gini_test, '--r', label='Teste')
leg = ax.legend()

grid2 = list(range(1, 1000, 20))
len(grid2)

lista_gini_test = []
lista_gini_train = []

for num_arvores in grid2:
  clf = RandomForestClassifier(n_estimators=num_arvores,
                               max_depth=10,
                               min_samples_leaf=5,
                               n_jobs=-1)

  clf.fit(X_train, y_train.ravel())

  gini_test = calcular_gini(y_test, clf.predict_proba(X_test)[:, 1])
  gini_train = calcular_gini(y_train, clf.predict_proba(X_train)[:, 1])

  lista_gini_test.append(gini_test)
  lista_gini_train.append(gini_train)

fig, ax = plt.subplots()

ax.plot(lista_gini_train, '-b', label="DES")
ax.plot(lista_gini_test, '--r', label='OOS')

leg = ax.legend()
ticks =  ax.set_xticks(range(0, len(grid), 10))
labels = ax.set_xticklabels(labels=grid[::10], rotation=30, fontsize='small')

"""### Função GridSearchCV"""

from sklearn.model_selection import GridSearchCV

rf = RandomForestClassifier()

params = {
    'max_depth': [10],
    'min_samples_leaf': [5],
    'n_estimators': list(range(1, 1001, 500))
}

grid_rf = GridSearchCV(estimator=rf,
                       param_grid=params,
                       scoring='accuracy',
                      cv=5)

grid_rf.fit(X_train, y_train)

grid_rf.cv_results_['params']

grid_rf.best_estimator_

grid_rf.best_estimator_.score(X_test, y_test)

grid_rf.score(X_test, y_test)

"""### Função RandomizedSearchCV"""

from sklearn.model_selection import RandomizedSearchCV

rf = RandomForestClassifier()

params = {
    'max_depth': [10],
    'min_samples_leaf': [5],
    'n_estimators': list(range(100, 1001, 100))
}

grid_rf = RandomizedSearchCV(n_iter=7,
                           estimator=rf,
                           param_distributions=params,
                           scoring='accuracy',
                           cv=3)

grid_rf.fit(X_train, y_train)

grid_rf.best_estimator_

grid_rf.score(X_test, y_test)

"""### Grid Search 2 - Usando for para variar o número mínimo de observações por folha"""

grid3 = list(range(2, 5000, 100))
grid3

lista_gini_test = []
lista_gini_train = []

grid3 = list(range(2, 5000, 100))

for num_min_obs in grid3:
  clf = RandomForestClassifier(n_estimators=30,
                               max_depth=10,
                               min_samples_leaf=num_min_obs,
                               n_jobs=-1)

  clf.fit(X_train, y_train.ravel())

  gini_test = calcular_gini(y_test, clf.predict_proba(X_test)[:, 1])
  gini_train = calcular_gini(y_train, clf.predict_proba(X_train)[:, 1])

  lista_gini_test.append(gini_test)
  lista_gini_train.append(gini_train)

dict_gini_train = dict(zip(list(range(2, 5000, 100)), lista_gini_train))
dict_gini_test = dict(zip(list(range(2, 5000, 100)), lista_gini_test))

series_gini_train = pd.Series(dict_gini_train)
series_gini_test = pd.Series(dict_gini_test)

fig, ax = plt.subplots()

ax.plot(series_gini_train, '-b', label="Treino")
ax.plot(series_gini_test, '--r', label='Teste')

leg = ax.legend()
ax.set_title("Random Forest - Gini vs N mínimo por folha")
ax.set_xlabel("Número mínimo de observações por folha")
ax.set_ylabel("Gini")

"""### Grid Search 3 - Variando a profundidade da árvore"""

lista_gini_test = []
lista_gini_train = []

grid4 = list(range(1, 50))

for profundidade in grid4:
  clf = RandomForestClassifier(n_estimators=30,
                               max_depth=profundidade,
                               min_samples_leaf=1,
                               n_jobs=-1)

  clf.fit(X_train, y_train.ravel())

  gini_test = calcular_gini(y_test, clf.predict_proba(X_test)[:, 1])
  gini_train = calcular_gini(y_train, clf.predict_proba(X_train)[:, 1])

  lista_gini_test.append(gini_test)
  lista_gini_train.append(gini_train)

dict_gini_train = dict(zip(grid4, lista_gini_train))
dict_gini_test = dict(zip(grid4, lista_gini_test))

series_gini_train = pd.Series(dict_gini_train)
series_gini_test = pd.Series(dict_gini_test)

fig, ax = plt.subplots()

ax.plot(series_gini_train, '-b', label="Treino")
ax.plot(series_gini_test, '--r', label='Teste')

leg = ax.legend()
ax.set_title("Random Forest - Gini vs Profundidade")
ax.set_xlabel("Profundidade")
ax.set_ylabel("Gini")

"""### Grid Search 4 - Variando dois hiperparâmetros juntos"""

lista_gini_test = []
lista_gini_train = []
lista_obs_folha = []
lista_profundidade = []

grid_profund = list(range(3, 20, 2))
grid_obs_folha = list(range(1, 30, 1))

for profundidade in grid_profund:
  for obs_folha in grid_obs_folha:
    clf = RandomForestClassifier(n_estimators=30,
                                max_depth=profundidade,
                                min_samples_leaf=obs_folha,
                                n_jobs=-1)

    clf.fit(X_train, y_train.ravel())

    gini_test = calcular_gini(y_test, clf.predict_proba(X_test)[:, 1])
    gini_train = calcular_gini(y_train, clf.predict_proba(X_train)[:, 1])

    lista_gini_test.append(gini_test)
    lista_gini_train.append(gini_train)
    lista_obs_folha.append(obs_folha)
    lista_profundidade.append(profundidade)

grid_dict = {'obs_folha': lista_obs_folha,
             'profund_max': lista_profundidade,
             'gini_dev': lista_gini_train,
             'gini_test': lista_gini_test}

grid = pd.DataFrame(grid_dict)
grid

sns.heatmap(grid.pivot_table(index='profund_max',
                             columns='obs_folha',
                             values='gini_test',
                             aggfunc='mean'))

grid[(grid['gini_test'] == 0.22266828178756048)]