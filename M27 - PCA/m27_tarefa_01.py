# -*- coding: utf-8 -*-
"""m27_tarefa_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m5RiN_Ei-bWJoqNIiU9pQuz8yyCh3fMf
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.tree import DecisionTreeClassifier

from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

filename_features = "/content/features.txt"
filename_labels = "/content/activity_labels.txt"

filename_subtrain = "/content/subject_train.txt"
filename_xtrain = "/content/X_train.txt"
filename_ytrain = "/content/y_train.txt"

filename_subtest = "/content/subject_test.txt"
ffilename_xtest = "/content/X_test.txt"
filename_ytest = "/content/y_test.txt"

# Rótulos, labels da atividade
features = pd.read_csv(filename_features, header=None, names=['nome_var'], sep="#")['nome_var']
labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])

# Treino
subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'])['subject_id']
X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features.tolist())
y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])

# Teste
subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id'])['subject_id']
X_test = pd.read_csv(ffilename_xtest, delim_whitespace=True, header=None, names=features.tolist())
y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])

"""# 1. Árvore de decisão
Rode uma árvore de decisão com todas as variáveis, usando `ccp_alpha=0.001`. Avalie a acurácia nas bases de treinamento e teste. Avalie o tempo de processamento
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# clf = DecisionTreeClassifier(random_state=1234, ccp_alpha=0.001)
# 
# clf.fit(X_train, y_train)
# 
# print(f"Treino: {clf.score(X_train, y_train) * 100:.2f}%")
# print(f"Teste: {clf.score(X_test, y_test) * 100:.2f}%")

"""# 2. Árvore com PCA
Faça uma análise de componentes principais das variáveis originais. Utilize apenas um componente. Faça uma árvore de decisão apenas com esta componente como variável explicativa.
- Avalie a acurácia nas bases de treinamento e teste
- Avalie o tempo de processamento
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# prcomp = PCA(n_components=1).fit(X_train)
# 
# pc_treino = prcomp.transform(X_train)
# pc_teste  = prcomp.transform(X_test)
# 
# pc_treino.shape

# Commented out IPython magic to ensure Python compatibility.
# %%time
# clf = DecisionTreeClassifier(random_state=1234, ccp_alpha=0.001).fit(pc_treino, y_train)
# 
# print(f"Treino: {clf.score(pc_treino, y_train) * 100:.2f}%")
# print(f"Teste: {clf.score(pc_teste, y_test) * 100:.2f}%")

"""# 3. Testando o número de componentes
Com base no código acima, teste a árvore de classificação com pelo menos as seguintes possibilidades de quantidade de componentes: `[1, 2, 5, 10, 50]`. Avalie para cada uma delas:
- Acurácia nas bases de treino e teste
- Tempo de processamento
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# components = [1, 2, 5, 10, 50]
# 
# for comp in components:
#   print("\nComponentes:", comp)
# 
#   prcomp = PCA(n_components=comp).fit(X_train)
# 
#   X_train_pca = prcomp.fit_transform(X_train)
#   X_test_pca = prcomp.transform(X_test)
# 
#   clf = DecisionTreeClassifier(random_state=1234, ccp_alpha=0.001)
# 
#   clf.fit(X_train_pca, y_train)
# 
#   print(f"Treino: {clf.score(X_train_pca, y_train) * 100:.2f}%")
#   print(f"Teste: {clf.score(X_test_pca, y_test) * 100:.2f}%")

"""## Acurácia X Tempo de Processamento
### Análise Comparativa de Acurácia
Quantidade de Componentes | Acurácia (Treino) | Acurácia (Teste)
---------|-----------|------|
1 Componente | 49.97% | 45.71% (Underfitting devido à informação insuficiente)
2 Componentes | 61.28% | 58.47%
5 Componentes | 84.60% | 78.89%
10 Componentes | 89.27% | 82.39% (Melhor resultado com PCA)
50 Componentes | 91.93% | 82.29%
Original (561 variáveis) | 97.58% | 87.95% (**Referência de melhor acurácia**)

- Com apenas 10 componentes, já conseguimos chegar em 82.39% de acurácia no teste. Isso prova que a maior parte da variânca dos dados de sensores está concentrada em poucas dimensões.
- O ganho de acurácia estagnou entre 10 e 50 componentes (82.39% vs 82.29%). Isso indica que, para este conjunto de dados e este nível de poda, 10 componentes são suficientes. Adicionar mais 40 variáveis só aumentou o overfitting sem trazer ganho real no teste.
- Outro detalhe interessante:
Quantidade de componentes | Acurácia no Treino | Acurácia no Teste
----------|-------------|--------|
10 Componentes	|89.27%	|82.39%
50 Componentes	|91.93%|	82.29%

A acurácia no treino com 50 componentes foi maior do que a acurácia no treino com com 10 componentes. Porém, a acurácia no teste com 50 componentes foi MENOR do que com 10 componentes.

Isso representa um padrão de comportamento: provavelmente, a partir de 50 componentes, a árvore começa a "memorizar" os dados de treinamento, o que leva a um overfitting. Esse padrão se mostra presente na árvore original também, porém a PCA pode estar facilitando isso.

Houve um ganho de velocidade. O tempo total de processamento para testar TODOS os cinco cenários de PCA (1 a 50 componentes) foi de 5.26 segundos, enquanto a árvore original sozinha levou 11.6 segundos.

Nesse sentido, treinar a árvore com PCA é bem mais rápido do que treinar as 561 variáveis originais. Isso traz a vantagem de economizar memória e latência de resposta.

Porém, há uma perda de acurácia (cerca de 5.5% pontos percentuais - 87.95% vs 82.39%). Por isso, é preciso avaliar o custo-benefício do modelo:
- Se o objetivo é um protótipo rápido ou um sistema que rode em hardware limitado, o ganho de velocidade compensa a perda de acurácia;
- Porém, dependendo do sistema (sistema para fins médicos, por exemplo, ou segurança), 8% de erro adicional pode ser inaceitável.
"""