# -*- coding: utf-8 -*-
"""capture_a_informacao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EKzwDYpRCtL15bvSr4EABvhg8yiTCkTf
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.tree import DecisionTreeClassifier

from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

df = pd.read_feather('notas.ftr')
df.head()

variaveis = ['por_p1', 'por_p2']

df[variaveis].head()

pca = PCA() # Definir o modelo
princomp = pca.fit(df[variaveis]) # Fazer um fit

componentes = princomp.transform(df[variaveis])]

principalDf = pd.DataFrame(data=componentes,
                           columns=['CP1', 'CP2'])

princomp

componentes

principalDf

princomp.components_

princomp.explained_variance_

princomp.explained_variance_ratio_

princomp.explained_variance_.sum()

7.230202 + 6.660342

princomp.explained_variance_ / princomp.explained_variance_.sum()

df[variaveis].cov()

principalDf.cov()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
X = df[variaveis]

fig = plt.figure(figsize=(10, 10))
ax = fig.add_subplot(1, 1, 1)

x_med = X.iloc[:, 0].mean()
y_med = X.iloc[:, 1].mean()

ax.scatter(x = X.iloc[:, 0], y = X.iloc[:, 1])

ampli_x = X.iloc[:, 0].max() - X.iloc[:, 0].min()
ampli_y = X.iloc[:, 1].max() - X.iloc[:, 1].min()

xmin = X.iloc[:, 0].min() - ampli_x *.1
xmax = X.iloc[:, 0].max() + ampli_x *.1
ymin = X.iloc[:, 1].min() - ampli_y *.1
ymax = X.iloc[:, 1].max() + ampli_y *.1

# ax.axis('equal')
ax.set_aspect('equal', 'box')
ax.set(xlim=(xmin, xmax), ylim=(ymin, ymax));

autovet=princomp.components_

ax.arrow(x_med, y_med, autovet[0, 0], autovet[1, 0],
         head_width=0.25,
         head_length=0.1,
         fc='g', ec='g',
         length_includes_head=True)
ax.arrow(x_med, y_med, autovet[0, 1], autovet[1, 1],
         head_width=0.25,
         head_length=0.1,
         fc='g', ec='g',
         length_includes_head=True)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook

fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(projection='3d')

variaveis = ['mat_p1', 'mat_p2', 'mat_p3']

pca = PCA()
princomp = pca.fit_transform(df[variaveis])
autovet=pca.components_
autoval = pca.explained_variance_

ax.scatter(df[variaveis[0]], df[variaveis[1]], df[variaveis[2]] )

for i, v in enumerate(autovet):
    ax.plot([df[variaveis[0]].mean(), df[variaveis[0]].mean() + v[0] * autoval[i] **.5],
            [df[variaveis[1]].mean(), df[variaveis[1]].mean() + v[1] * autoval[i] **.5],
            [df[variaveis[2]].mean(), df[variaveis[2]].mean() + v[2] * autoval[i] **.5],
            color='red',
            alpha=0.8,
            lw=3)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig, ax = plt.subplots(figsize=(15, 15))

# calcula a matriz de correlação
corr = df.corr()

# Generate a mask for the upper triangle
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True


# Draw the heatmap with the mask and correct aspect ratio
vmax = np.abs(corr.values[~mask]).max()
sns.heatmap(corr, mask=mask, cmap=plt.cm.PuOr, vmin=-vmax, vmax=vmax,
            square=True, linecolor="lightgray", linewidths=1, ax=ax)
for i in range(len(corr)):
    # Coloca o texto na diagonal principal
    ax.text(i+0.5,(i+0.5), corr.columns[i],
            ha="center", va="center", rotation=45)
    for j in range(i+1, len(corr)):
        s = "{:.3f}".format(corr.values[i,j]).replace(".",",")
        ax.text(j+0.5,(i+0.5),s,
            ha="center", va="center")

ax.axis("off")
plt.show()

pca = PCA()

n_componentes = df.shape[1]

princomp = pca.fit(df)

componentes = princomp.transform(df)

nomes_pca = ['CP'+str(x+1) for x in list(range(n_componentes))]

principalDf = pd.DataFrame(data = componentes,
                           columns = nomes_pca)

principalDf

princomp.explained_variance_

princomp.explained_variance_ratio_

princomp.explained_variance_ratio_.cumsum()

