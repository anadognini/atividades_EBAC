# -*- coding: utf-8 -*-
"""determine_quantos_componentes_utilizar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14NxxZDoSiofPMeNxUd7rdgpjx_CNDpiS
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.tree import DecisionTreeClassifier

from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from keras.datasets.mnist import load_data

(X_train, y_train), (X_test, y_test) = load_data()

X_train.shape

pd.set_option("display.max_columns", None)

pd.DataFrame(X_train[0])

i = 0

plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))
print(f'O número é o {y_train[i]}')

sns.boxplot(x=y_train, y=X_train[:, 14, 14])

X_tra = X_train.reshape(X_train.shape[0], 784)
X_tst = X_test.reshape(X_test.shape[0], 784)

X_tra.shape

clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_tra, y_train)

y_pred = clf.predict(X_tst)
print(f'A acurácia na base de testes é: {accuracy_score(y_pred, y_test) * 100:.2f}%')

ConfusionMatrixDisplay.from_predictions(y_test, y_pred)

prcomp = PCA().fit(X_tra)

def screeplot(princomp, ncomp = 0, varexplicada=0, criterio=1):

    if ncomp>0:
        ncomp_crit=ncomp
    elif varexplicada > 0:
        ncomp_crit = (princomp.explained_variance_ratio_.cumsum()<varexplicada).sum()+1
        # Critério 1: autovalor padronizado > 1
    elif criterio == 1:
        ncomp_crit = (princomp.explained_variance_ratio_>1/princomp.n_components_).sum()
    else: ncomp_crit = None

    fig, ax = plt.subplots(2, 2, sharex=True, figsize=(14, 8))
    plt.subplots_adjust(hspace=0, wspace=.15)

    num_componentes = np.arange(princomp.n_components_) + 1
    ax[0, 0].plot(num_componentes, princomp.explained_variance_, 'o-', linewidth=2, color='blue', markersize=2, alpha=.2)
    ax[0, 0].set_title('Scree Plot - Variância total')
    ax[0, 0].set_xlabel('Número de componentes')
    ax[0, 0].set_ylabel('Variancia explicada (Autovalores)')

    ax[1, 0].plot(num_componentes, princomp.explained_variance_.cumsum(), 'o-', linewidth=2, color='blue', markersize=2, alpha=.2)
    ax[1, 0].set_xlabel('Número de componentes')
    ax[1, 0].set_ylabel('Variancia explicada (Acumulada)')


    ax[0, 1].plot(num_componentes, princomp.explained_variance_ratio_, 'o-', linewidth=2, color='blue', markersize=2, alpha=.2)
    ax[0, 1].set_title('Scree Plot - Variância percentual')
    ax[0, 1].set_xlabel('Número de componentes')
    ax[0, 1].set_ylabel('Variancia explicada (percentual)')

    ax[1, 1].plot(num_componentes, princomp.explained_variance_ratio_.cumsum(), 'o-', linewidth=2, color='blue', markersize=2, alpha=.2)
    ax[1, 1].set_xlabel('Número de componentes')
    ax[1, 1].set_ylabel('Variancia explicada (% Acumulado)')

    if ncomp_crit != None:
        # Linhas verticais de referência
        ax[0, 0].axvline(x = ncomp_crit, color = 'r', linestyle = '-', linewidth=.5)
        ax[1, 1].axvline(x = ncomp_crit, color = 'r', linestyle = '-', linewidth=.5)
        ax[1, 0].axvline(x = ncomp_crit, color = 'r', linestyle = '-', linewidth=.5)
        ax[0, 1].axvline(x = ncomp_crit, color = 'r', linestyle = '-', linewidth=.5)


        # linhas horizontais
        variancia               = princomp.explained_variance_[ncomp_crit-1]
        variancia_acumulada     = princomp.explained_variance_.cumsum()[ncomp_crit-1]
        pct_variancia           = princomp.explained_variance_ratio_[ncomp_crit-1]
        pct_variancia_acumulada = princomp.explained_variance_ratio_.cumsum()[ncomp_crit-1]

        ax[0, 0].axhline(y = variancia, color = 'r', linestyle = '-', linewidth=.5)
        ax[1, 0].axhline(y = variancia_acumulada, color = 'r', linestyle = '-', linewidth=.5)
        ax[0, 1].axhline(y = pct_variancia, color = 'r', linestyle = '-', linewidth=.5)
        ax[1, 1].axhline(y = pct_variancia_acumulada, color = 'r', linestyle = '-', linewidth=.5)


    print(f'Número de componentes: {ncomp_crit}')
    print(f'Variância da ultima CP: {variancia:.2f}' )
    print(f'Variância total explicada: {variancia_acumulada:.2f}' )
    print(f'Variância percentual da última CP: {100*pct_variancia:.2f}%' )
    print(f'Variância percentual total explicada: {100*pct_variancia_acumulada:.2f}%' )
    plt.show()

    return ncomp_crit

ncomp = screeplot(prcomp, varexplicada=.80)

prcomp = PCA(n_components=ncomp).fit(X_tra)
cp_tr = prcomp.transform(X_tra)
cp_ts = prcomp.transform(X_tst)

sns.boxplot(x=y_train, y=cp_tr[:, 0])

cp_tr.shape

clf=RandomForestClassifier(n_estimators=100)
clf.fit(cp_tr, y_train)

y_pred=clf.predict(cp_ts)
print(f'Acurácia na base de testes é: {accuracy_score(y_pred, y_test) * 100:.2f}%')

ConfusionMatrixDisplay.from_predictions(y_test, y_pred)

X_trcp = pd.concat([pd.DataFrame(cp_tr), pd.DataFrame(X_tra)], axis=1)

cor_cp = X_trcp.corr().iloc[10:, :10].to_numpy()
cor_cp.shape

plt.imshow(cor_cp[34:, 3].reshape(28, 28))

cor_cp[34:, 4].shape

