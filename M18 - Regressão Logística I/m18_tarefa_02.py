# -*- coding: utf-8 -*-
"""m18_tarefa_02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aOMHEsmoK_cz2UdZ6FwRD0dAl7ULd1Bp

# Regressão Logística I
## Tarefa II

Vamos trabalhar com a mesma base do exercício anterior, mas vamos aprofundar um pouco mais a nossa regressão.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

import statsmodels.formula.api as smf

url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'

df = pd.read_csv(url,
                 names=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',
                        'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'])
df['flag_doente'] = (df['num']!=0).astype('int64')
df.head()

df.dtypes

"""A descrição das variáveis está recortada abaixo:
- age: idade do paciente em anos
- sex: sexo (1 = male; 0 = female)  
- cp: tipo de dor no peito
  - 1: angina típica
  - 2: angina atípica
  - 3: dor não-angina
  - 4: assintomático
- trestbps: pressão sanguínea em repouso (em mm Hg na admissão ao hospital
- chol: colesterol sérico em mg/dl
- fbs: (açúcar no sangue em jejum > 120 mg/dl) (1 = True; 0 = False)
- restecg: resultados eletrocardiográficos em repouso
  - 0: normal
  - 1: tendo anormalidade da onda ST-T (Inversões de onda T e / ou ST com elevação ou depressão de > 0.05 mV)
  - 2: mostrando hipertrofia ventricular esquerda provável ou definitiva pelos critérios de Estes
- thalach: frequência cardíaca máxima alcançada
- exang: angina induzida por exercício(1 = sim; 0 = não)
- oldpeak = Depressão de ST induzida por exercício em relação ao repouso
- slope: Depressão de ST induzida por exercício em relação ao repouso
  - 1: inclinação ascendente
  - 2: estável
  - 3: inclinação descendente
- ca: número de vasos principais (0-3) coloridos por fluorosopia
- thal: 3 = normal; 6 = defeito corrigido; 7 = defeito reversível
- num: diagnóstico de doença cardíaga (status de doença angiográfica)
"""

df.info()

"""1. Considere o script que monta a análise bivariada que você fez na tarefa anterior. Transforme esse script em uma função, que deve:
- Ter como parâmetros de entrada:
    - Um *dataframe* contendo os dados a serem avaliados
    - Um *string* contendo o nome da variável resposta
    - Um *string* contendo o nome da variável explicativa
- E deve retornar um *dataframe* com os dados da bivariada.
**Monte** a mesma bivariada pelo menos três variáveis qualitativas do *data-frame*. Qual delas parece discriminar mais o risco?
"""

def bivariada(df, y, x): # considerando-se que y é a variável-resposta e x a variável explicativa
  biv = (df.groupby(x)[y]
        .agg(doentes='sum', total='count')
    )

  biv['saudaveis'] = biv['total'] - biv['doentes']
  biv['media_doentes'] = biv['doentes'] / biv['total']
  biv['odds'] = biv['doentes'] / biv['saudaveis']

  # Odds total
  total_doentes = df[y].sum()
  total_saudaveis = len(df) - total_doentes
  odds_total = total_doentes / total_saudaveis

  biv['odds_ratio'] = biv['odds'] / odds_total
  biv['logito'] = np.log(biv['odds'])
  biv['woe'] = np.log(biv['odds_ratio'])

  return biv

biv_sex = bivariada(df, 'flag_doente', 'sex')
biv_sex

biv_cp = bivariada(df, 'flag_doente', 'cp')
biv_cp

biv_exang = bivariada(df, 'flag_doente', 'exang')
biv_exang

"""Para determinar qual variável discrimina melhor o risco, usaremos o seguinte critério:
- Amplitude máxima do WOE: mede o contraste extremo entre um grupo e o total:
max(|WOE|)

Calculando a amplitude de cada variável, obtemos:
- `sex` ≈ 0.892
- `cp` ≈ 1.350
- `exang` ≈ 1.360

A variável de maior amplitude é `exang`. Portanto, `exang` é a variável que mais faz discriminação extrema do risco segundo esse critério.

2. Monte uma função semelhante para categorizar variáveis quantitativas contínuas (com muitas categorias) como ```age```.  
    Além dos mesmos parâmetros da função anterior, defina mais um parâmetro como número de categorias que você deseja quebrar. Defina um valor '*default*' de 5 grupos para este parâmetro.
"""

def bivariada_quantitativa (df, y, x, n_grupos=5):
  df_aux = df.copy()
  df_aux[f'{x}_cat'] = pd.qcut(df_aux[x], q=n_grupos, duplicates='drop')

  biv = (df_aux.groupby(f'{x}_cat')[y]
        .agg(doentes='sum', total='count')
  )

  biv['saudaveis'] = biv['total'] - biv['doentes']
  biv['media_doentes'] = biv['doentes'] / biv['total']
  biv['odds'] = biv['doentes'] / biv['saudaveis']

  # Odds total
  total_doentes = df_aux[y].sum()
  total_saudaveis = len(df_aux) - total_doentes
  odds_total = total_doentes / total_saudaveis

  biv['odds_ratio'] = biv['odds'] / odds_total
  biv['logito'] = np.log(biv['odds'])
  biv['woe'] = np.log(biv['odds_ratio'])

  return biv

biv_age = bivariada_quantitativa(df, 'flag_doente', 'age', n_grupos=10)
biv_age

"""3. Construa um modelo de regressão logística com as variáveis qualitativas: ```sex + cp +  trestbps``` e com a variável quantitativa ```age```.

**Interprete os parâmetros.**
"""

reglog = smf.logit("flag_doente ~ sex + C(cp) + trestbps + age", data=df).fit()
reglog.summary()

"""4. Avalie o seu modelo quanto a **calibragem**:
- Calcule a probabilidade de evento predita segundo o seu modelo
- Categorize essa probabilidade em G=5 grupos
- Calcule a probabilidade de evento predita média por grupo
- Calcule a taxa de eventos (média da variável indicadora de eventos) por grupo
- Compare graficamente o valor eperado versus observado para a taxa de maus por grupo
"""

df['predito'] = reglog.predict(df)

df['cat_pred'] = pd.qcut(df['predito'], 5, duplicates='drop')
df['cat_pred'].value_counts().sort_index()

group_reg = df.groupby('cat_pred')

calib = group_reg['flag_doente'].count().to_frame('contagem')
calib['media_predita'] = group_reg['predito'].mean()
calib['taxa_observada'] = group_reg['flag_doente'].mean()
calib

fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)

ax = calib['media_predita'].plot(label='Probabilidade Predita')
ax = calib['taxa_observada'].plot(label='Taxa Observada')

ticks = ax.set_xticks([0, 1, 2, 3, 4])
labels = ax.set_xticklabels([1, 2, 3, 4, 5])
ax.legend(loc='lower right')
ax.set_xlabel('Grupo de Risco')
ax.set_ylabel('Probabilidade de Evento')

plt.show()

"""5. Avalie o seu modelo quanto a discriminação calculando acurácia, GINI e KS."""

from sklearn import metrics
from scipy.stats import ks_2samp

acc = metrics.accuracy_score(df['flag_doente'], df['predito'] >= 0.5)
print("Acurácia: {0:.2f}%".format(acc*100))

# AUC
fpr, tpr, thresholds = metrics.roc_curve(df['flag_doente'], df['predito'])
auc_ = metrics.auc(fpr, tpr)

# Gini
gini = 2 * auc_ - 1

# KS
ks = ks_2samp(df.loc[df['flag_doente'] == 1, 'predito'], df.loc[df['flag_doente'] != 1, 'predito']).statistic

print('KS: {0:.2f}% \nAUC: {1:.2f}% \nGini: {2:.2f}%'.format(ks*100, auc_*100, gini*100))

"""6. Tente melhorar o modelo obtido, por exemplo inserindo ou removendo variáveis.  
    Avalie as características do seu modelo (calibragem e acurácia).
"""

# C(cp)[T.2.0] e C(cp)[T.3.0] são bem insignificantes estatisticamente. Não
# contribuem para o modelo.

# Agrupando categorias com comportamento semelhante (baseado no WOE)
df['cp_bin'] = df['cp'].replace({1: 0, 2: 0, 3: 0, 4: 1})

reglog2 = smf.logit("flag_doente ~ sex + trestbps + age + cp_bin", data=df).fit()
reglog2.summary()

# Modelando age de forma não linear
df['age2'] = df['age'] ** 2

reglog3 = smf.logit("flag_doente ~ sex + trestbps + cp_bin + age2", data=df).fit()
reglog3.summary()

# Inserindo uma variável forte. Como já vimos antes, exang tem WOE bem alto
reglog4 = smf.logit("flag_doente ~ sex + trestbps + cp_bin + age2 + exang", data=df).fit()
reglog4.summary()

df['predito2'] = reglog4.predict(df)

acc = metrics.accuracy_score(df['flag_doente'], df['predito2'] >= 0.5)
print("Acurácia: {0:.2f}%".format(acc*100))

# AUC
fpr, tpr, thresholds = metrics.roc_curve(df['flag_doente'], df['predito2'])
auc_ = metrics.auc(fpr, tpr)

# Gini
gini = 2 * auc_ - 1

# KS
ks = ks_2samp(df.loc[df['flag_doente'] == 1, 'predito2'], df.loc[df['flag_doente'] != 1, 'predito2']).statistic

print('KS: {0:.2f}% \nAUC: {1:.2f}% \nGini: {2:.2f}%'.format(ks*100, auc_*100, gini*100))

"""Comparando:
1º modelo:
- Acurácia: 79.54%
- KS: 59.30%
- AUC: 85.19%
- Gini: 70.39%

2ª modelo:
- Acurácia: 78.55%
- KS: 61.00%
- AUC: 86.50%
- Gini: 73.00%

A acurácia deu ligeiramente menor, porém todas as outras métricas aumentaram. A acurácia depende do ponto de corte e é menos informativa no contexto de modelagem de risco. Além disso, o modelo final apresenta coeficientes estatisticamente mais significativas.
"""