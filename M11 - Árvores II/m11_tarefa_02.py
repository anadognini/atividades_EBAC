# -*- coding: utf-8 -*-
"""m11_tarefa_02

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IOEH1ary8S3jrbBaCBisNOsAbRryvC7m

## Árvores de regressão - exercícios 02

Este exercício será uma continuação do anterior, mesma base, mesmas variáveis - vamos tentar buscar a 'melhor árvore'.

*Atenção - Utilizar a base de dados em anexo que é a mesma base que utilizamos na atividade anterior! A base Boston, assim como para a primeira atividade foi descontinuada e não deve ser utilizada*
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor
from sklearn import tree
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import train_test_split

"""### 1. Execute os passos do exercício anterior, até que você tenha uma árvore de regressão predizendo o valor do imóvel na base de treinamento."""

housing = pd.read_csv('housing.csv')
housing.head()
housing.info()
housing.isnull().sum()

X = housing.drop('median_house_value', axis=1)  # variáveis explicativas
y = housing['median_house_value']               # variável alvo

X = pd.get_dummies(X, drop_first=True)
X = X.fillna(X.median())

corr = housing.corr(numeric_only=True)

plt.figure(figsize=(12, 8))
sns.heatmap(corr, cmap='crest', annot=False, center=0)
plt.title('Matriz de Correlação - Base Housing (Califórnia)', fontsize=14)
plt.show()

corr_target = corr['median_house_value'].sort_values(ascending=False)
print(corr_target)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.dtypes)
print(X_train.isnull().sum().sum())

arvore_8 = DecisionTreeRegressor(max_depth=4, random_state=42)
arvore_8.fit(X_train, y_train)

y_pred_train_8 = arvore_8.predict(X_train)
y_pred_test_8 = arvore_8.predict(X_test)

mse_train_8 = mean_squared_error(y_train, y_pred_train_8)
mse_test_8  = mean_squared_error(y_test, y_pred_test_8)

print(f"Árvore (max_depth=8): MSE Treino = {mse_train_8:.2f} | MSE Teste = {mse_test_8:.2f}")

plt.rc('figure', figsize=(10, 10))

tp = tree.plot_tree(arvore_8,
                    feature_names=X.columns,
                    filled=True)

representaca_textual = tree.export_text(arvore_8)
print(representaca_textual)

"""### 2.  Calcule o caminho indicado pelos CCP-alfas dessa árvore."""

path = arvore_8.cost_complexity_pruning_path(X_train, y_train)
path

"""### 3. Para cada valor de alpha obtido no item 2, treine uma árvore com o respectivo alfa e guarde essa árvore em uma lista."""

ccp_alphas, impurities = path.ccp_alphas, path.impurities

clfs = []

for ccp_alpha in ccp_alphas:
  clf = DecisionTreeRegressor(random_state=0, ccp_alpha=ccp_alpha)
  clf.fit(X_train, y_train)
  clfs.append(clf)

clfs

"""### 4. Para cada árvore na lista, calcule o MSE da árvore."""

train_scores = [mean_squared_error(y_train, clf.predict(X_train)) for clf in clfs]
test_scores = [mean_squared_error(y_test, clf.predict(X_test)) for clf in clfs]

best_alpha = ccp_alphas[np.argmin(test_scores)]
plt.axvline(best_alpha, color='red', linestyle='--', label=f'Melhor alpha = {best_alpha:.5f}')
plt.legend()

"""### 5. Monte um gráfico do MSE pelo alpha, escolha um valor de alpha perto do ponto de mínimo do MSE"""

fig, ax = plt.subplots()
ax.set_xlabel("Alpha efetivo")
ax.set_ylabel("MSE")
ax.set_title("MSE X Alpha do conjunto de dados de treino e teste")
ax.plot(ccp_alphas[:-1], train_scores[:-1], marker='o', label="treino",
        drawstyle="steps-post")
ax.plot(ccp_alphas[:-1], test_scores[:-1], marker='o', label="teste",
        drawstyle="steps-post")
ax.legend()
plt.show()

"""### 6. Calcule o R-quadrado dessa árvore encontrada no item acima"""

best_alpha = ccp_alphas[np.argmin(test_scores)]

arvore_final = DecisionTreeRegressor(random_state=42, ccp_alpha=best_alpha)
arvore_final.fit(X_train, y_train)

y_pred_final = arvore_final.predict(X_test)
print("MSE final:", mean_squared_error(y_test, y_pred_final))
print("R² final:", r2_score(y_test, y_pred_final))

"""### 7. Visualize esta árvore."""

plt.figure(figsize=(14, 8))
tree.plot_tree(arvore_final, feature_names=X.columns, filled=True)
plt.show()