# -*- coding: utf-8 -*-
"""M11_tarefa_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aQIedJdrSpwyQs0hIo2qA4IAojaF-5bj

# Árvores de regressão - exercícios 01

*Atenção! Devido descontinuação da base de imóveis boston os alunos devem utilizar a base de dados que se encontra em anexo.*

A base que utilizaremos contem os dados dos imóveis da california.
Considerem como variável Target (a ser prevista) a coluna median_house_value.
O dataset é muito semelhante ao de boston, contendo localização, quartos, banheiros e outras variáveis interessantes para construção do modelo.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.tree import DecisionTreeRegressor
from sklearn import tree
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

"""### 1. Certifique-se de que esta base está no formato adequado para o scikitlearn.
ok, essa tarefa é tão fácil que você vai até desconfiar. Mas é preciso ter confiança sobre os dados que se usa ;)
"""

# Carregando a base de dados

housing = pd.read_csv('housing.csv')
housing.head()

# Informações sobre as colunas
housing.info()

# Verificando valores ausentes
housing.isnull().sum()

# Separando as variáveis explicativas da variável-alvo

X = housing.drop('median_house_value', axis=1)  # variáveis explicativas
y = housing['median_house_value']               # variável alvo

# A coluna ocean_proximity contém categorias como "INLAND", "NEAR BAY", etc.
# O Scikit-learn não aceita texto diretamente, então é preciso transformar essa
# variável em formato numérico ONe-Hot Encoding

X = pd.get_dummies(X, drop_first=True)

# Isso cria uma coluna para cada categoria (0 ou 1), permitindo que o modelo as
# use corretamente

# Se houver valores nulos (especialmente em total_bedrooms), substituímos pela
# mediana da coluna

X = X.fillna(X.median())

"""### 2.  Visualize a matriz de correlação, e veja se aparentemente você encontra alguma variável com potencial preditivo interessante."""

# Matriz de correlação

corr = housing.corr(numeric_only=True)

# Visualização da matriz

plt.figure(figsize=(12, 8))
sns.heatmap(corr, cmap='crest', annot=False, center=0)
plt.title('Matriz de Correlação - Base Housing (Califórnia)', fontsize=14)
plt.show()

"""Como interpretar a matriz de correlação

- Cada célula mostra o grau de relação linear entre duas variáveis.

- Os valores vão de -1 a +1:

  - +1 → correlação positiva perfeita (crescem juntas)

  - -1 → correlação negativa perfeita (uma cresce, outra diminui)

  - 0 → nenhuma correlação linear aparente
"""

# Como o objetivo é prever o median_house_value, podemos filtrar apenas a
# correlação dessa coluna

corr_target = corr['median_house_value'].sort_values(ascending=False)
print(corr_target)

"""É possível ver que a variável `median_house_value` é a mais importante, com maior correlação.

### 3. Separe os dados em validação e teste
"""

# Dividindo em treino e teste

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Verificando se tudo está pronto para o Scikit-learn. Ele exige que:
# - Todos os dados em X_train e X_test sejam numéricos;
# - Não haja NaN nem valores infinitos;
# - A variável resposta (y_train) seja vetor 1D numérico.

print(X_train.dtypes)
print(X_train.isnull().sum().sum())

"""### 4. Treine duas árvores, uma com profundidade máxima = 8, outra com profundidade máxima = 2."""

arvore_8 = DecisionTreeRegressor(max_depth=4, random_state=42)
arvore_8.fit(X_train, y_train)

arvore_2 = DecisionTreeRegressor(max_depth=2, random_state=42)
arvore_2.fit(X_train, y_train)

"""### 5. Calcule o MSE de cada uma das árvores do item anterior para a base de treinamento e para a base de testes."""

y_pred_train_8 = arvore_8.predict(X_train)
y_pred_test_8 = arvore_8.predict(X_test)

y_pred_train_2 = arvore_2.predict(X_train)
y_pred_test_2 = arvore_2.predict(X_test)

mse_train_8 = mean_squared_error(y_train, y_pred_train_8)
mse_test_8  = mean_squared_error(y_test, y_pred_test_8)

mse_train_2 = mean_squared_error(y_train, y_pred_train_2)
mse_test_2  = mean_squared_error(y_test, y_pred_test_2)

print(f"Árvore (max_depth=8): MSE Treino = {mse_train_8:.2f} | MSE Teste = {mse_test_8:.2f}")
print(f"Árvore (max_depth=2): MSE Treino = {mse_train_2:.2f} | MSE Teste = {mse_test_2:.2f}")

"""### 6. Com base nos resultados do item anterior, qual árvore te parece mais adequada?

Com base nos resultados, a árvore que me parece mais adequada é a árvore de profundidade 8. A diferença entre o MSE no treino e no teste não é tão grande quanto a diferença do MSE no treino e no teste da árvore de profundidade 2.

### 7. Faça uma visualização gráfica dessa árvore. Vamos discutir importância de variável mais adiante, mas veja a sua árvore, e pense um pouco: qual variável te parece mais "importante" na árvore?
"""

plt.rc('figure', figsize=(10, 10))

tp = tree.plot_tree(arvore_8,
                    feature_names=X.columns,
                    filled=True)

representaca_textual = tree.export_text(arvore_8)
print(representaca_textual)

"""A variável mais importante me parece ser a variável `median_income`, que corresponde à renda mediana, e é o fator com maior correlação com o valor das casas. Ela aparece na raiz da árvore, ou seja, é usada na primeira decisão do modelo. Isso significa que, antes de qualquer outra variável, o algoritmo separa os imóveis com base no valor dessa feature. Quando uma variável ocupa essa posição e é reutilizada várias vezes, isso indica que ela reduz fortemente o erro (MSE) a cada divisão e, por isso, o modelo "prefere" usá-la."""