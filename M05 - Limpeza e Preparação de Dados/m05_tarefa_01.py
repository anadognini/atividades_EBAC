# -*- coding: utf-8 -*-
"""m05_tarefa_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hQC4GSLzhQplrUworkGMhJQo85PhKMNP

# Módulo 5 Tarefa 1
## Base de nascidos vivos do DataSUS
O DataSUS disponibiliza diversos arquivos de dados com relação a seus segurados, conforme a [lei da transparência de informações públicas](https://www.sisgov.com/transparencia-acesso-informacao/#:~:text=A%20Lei%20da%20Transpar%C3%AAncia%20(LC,em%20um%20site%20na%20internet.).

Essas informações podem ser obtidas pela internet [aqui](http://www2.datasus.gov.br/DATASUS/index.php?area=0901&item=1). Como o processo de obtenção desses arquivos foge um pouco do nosso escopo, deixamos o arquivo ```SINASC_RO_2019.csv``` já como vai ser encontrado no DataSUS. O dicionário de dados está no arquivo ```estrutura_sinasc_para_CD.pdf``` (o nome do arquivo tal qual no portal do DataSUS).

### Nosso objetivo
Queremos deixar uma base organizada para podermos estudar a relação entre partos com risco para o bebê e algumas condições como tempo de parto, consultas de pré-natal etc.

#### Preparação da base
1. Carregue a base 'SINASC_RO_2019.csv'. Conte o número de registros e o número de registros não duplicados da base. Dica: você aprendeu um método que remove duplicados, encadeie este método com um outro método que conta o número de linhas. **Há linhas duplicadas?**  

2. Conte o número de valores *missing* por variável.  

3. Ok, no item anterior você deve ter achado pouco prático ler a informação de tantas variáveis, muitas delas nem devem ser interesantes. Então crie uma seleção dessa base somente com as colunas que interessam. São elas:
```
['LOCNASC', 'IDADEMAE', 'ESTCIVMAE', 'ESCMAE', 'QTDFILVIVO',
    'GESTACAO', 'GRAVIDEZ', 'CONSULTAS', 'APGAR5']
```
Refaça a contagem de valores *missings*.  

4. Apgar é uma *nota* que o pediatra dá ao bebê quando nasce de acordo com algumas características associadas principalmente à respiração. Apgar 1 e Apgar 5 são as notas 1 e 5 minutos do nascimento. Apgar5 será a nossa variável de interesse principal. Então remova todos os registros com Apgar5 não preenchido. Para esta seleção, conte novamente o número de linhas e o número de *missings*.  

5. observe que as variáveis ```['ESTCIVMAE', 'CONSULTAS']``` possuem o código ```9```, que significa *ignorado*. Vamos assumir que o não preenchido é o mesmo que o código ```9```.<br>
6. Substitua os valores faltantes da quantitativa (```QTDFILVIVO```) por zero.  
7. Das restantes, decida que valore te parece mais adequado (um 'não preenchido' ou um valor 'mais provável' como no item anterior) e preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do cientista, e que estamos tomando decisões a todo o momento - não há necessariamente certo e errado aqui.  
8. O Apgar possui uma classificação indicando se o bebê passou por asfixia:
- Entre 8 e 10 está em uma faixa 'normal'.
- Entre 6 e 7, significa que o recém-nascido passou por 'asfixia leve'.
- Entre 4 e 5 significa 'asfixia moderada'.
- Entre 0 e 3 significa 'asfixia severa'.  

Crie uma categorização dessa variável com essa codificação e calcule as frequências dessa categorização.  
<br>
9. Renomeie as variáveis para que fiquem no *snake case*, ou seja, em letras minúsculas, com um *underscore* entre as palávras. Dica: repare que se você não quiser criar um *dataframe* novo, você vai precisar usar a opção ```inplace = True```.
"""

import pandas as pd
import requests

# 1) Carregue a base 'SINASC_RO_2019.csv'. Conte o número de registros e o
# número de registros não duplicados da base. Dica: você aprendeu um método
# que remove duplicados, encadeie este método com um outro método que conta o
# número de linhas. Há linhas duplicadas?

sinasc = pd.read_csv('SINASC_RO_2019.csv')

# Primeiro, utilizamos o atributo shape para imprimir a quantidade total de
# linhas e colunas desse dataframe, utilizando a funçã print() para que essa
# informação seja impressa diretamente

print(sinasc.shape)

# Em seguida, utilizamos o método drop_duplicates(), que realiza a deleção
# de quaisquer linhas duplicadas que possam haver no dataframe e encadeamos a
# este método o atributo shape, para que possamos verificar novamente a
# quantidade de linhas e colunas dele.

sinasc.drop_duplicates().shape

# Por fim, comparamos as duas informações impressas para descobrir qual é
# a quantidade de valores duplicados totais no dataframe. Caso a quantidade
# de linhas fosse diferente entre as duas, saberíamos que essa quantidade.
# Em nosso dataframe, não há nenhum valor duplicado, pois é possível perceber
# que a quantidade de linhas permanece igual antes e depois do drop_duplicates()
# 27028.

sinasc.columns

sinasc.dtypes

sinasc

# 2) Conte o número de valores missing por variável.

# Ao utilizar o método isnull(), estamos criando uma cópia do dataframe
# original, porém com os valores substituídos por True (caso seja um
# valor vazio) e False (caso não seja)

# Em seguida, apliquei o método sum() ao dataframe e salvamos em uma
# variável. Esse método irá somar todos esses valores ao longo de
# cada coluna.

valores_vazios = sinasc.isnull().sum()

# Por fim, imprimimos a variável para que possamos ver o número de valores
# faltantes em cada coluna.

valores_vazios

# 3) Ok, no item anterior você deve ter achado pouco prático ler a informação
# de tantas variáveis, muitas delas nem devem ser interesantes. Então crie uma
# seleção dessa base somente com as colunas que interessam. São elas:

#['LOCNASC', 'IDADEMAE', 'ESTCIVMAE', 'ESCMAE', 'QTDFILVIVO',
# 'GESTACAO', 'GRAVIDEZ', 'CONSULTAS', 'APGAR5']

# Refaça a contagem de valores missings.

# Nesse exercício, iniciei selecionando as colunas  desejadas do dataframe
# sinasc e armazenando-as em uma lista

colunas_de_interesse = ['LOCNASC', 'IDADEMAE', 'ESTCIVMAE', 'ESCMAE',
                       'QTDFILVIVO', 'GESTACAO', 'GRAVIDEZ', 'CONSULTAS',
                        'APGAR5']

# Em seguida, selecionei as colunas na lista através da notação de colchetes,
# apliquei o método isnull() para realizar a contagem de valores vazios e,
# por fim, apliquei o método sum() para somar a quantidade total de valores
# vazios em cada uma dessas colunas. Isso tudo foi salvo numa variável que ao
# final da célula foi printada

valores_faltantes = sinasc[colunas_de_interesse].isnull().sum()

valores_faltantes

# 4) Apgar é uma nota que o pediatra dá ao bebê quando nasce de acordo com
# algumas características associadas principalmente à respiração. Apgar 1 e
# Apgar 5 são as notas 1 e 5 minutos do nascimento. Apgar5 será a nossa
# variável de interesse principal. Então remova todos os registros com Apgar5
# não preenchido. Para esta seleção, conte novamente o número de linhas e o
# número de missings.

# Para fins de comparação:

# Calculando o número total de linhas no DataFrame original "sinasc"
# usando a função len()

linhas_originais = len(sinasc)

# Calculo o número de valores ausentes (NaN) na coluna "APGAR5" do
# dataframe original usando o método isnull().sum(). Todos os valores calculados
# foram salvos em variáveis distintas

apgar5_faltantes = sinasc['APGAR5'].isnull().sum()

# 4) Apgar é uma nota que o pediatra dá ao bebê quando nasce de acordo com
# algumas características associadas principalmente à respiração. Apgar 1 e
# Apgar 5 são as notas 1 e 5 minutos do nascimento. Apgar5 será a nossa
# variável de interesse principal. Então remova todos os registros com Apgar5
# não preenchido. Para esta seleção, conte novamente o número de linhas e o
# número de missings.

# Criei um novo dataframe chamado "sinasc_limpo", que contém todas as linhas
# do dataframe original exceto aquelas que têm valores ausentes (NaN) na coluna
# "APGAR5". Isso é feito usando o método dropna()

sinasc.dropna(subset=['APGAR5'], inplace=True)

# Calculo também o número de linhas remanescentes no dataframe "sinasc_limpo",
# que é o número de linhas após a remoção das linhas com valores ausentes.

linhas_remanescentes = len(sinasc)

# Imprimindo as variáveis com os valores calculados

print("Quantidade de linhas no dataframe original:", linhas_originais)
print("Quantida de linhas remanescentes após a remoção dos valores faltantes:",
      linhas_remanescentes)
print("Quantidade de valores ausentes na coluna APGAR5:", apgar5_faltantes)

# 5) Observe que as variáveis ['ESTCIVMAE', 'CONSULTAS'] possuem o código 9,
# que significa ignorado. Vamos assumir que o não preenchido é o mesmo que o
# código 9. Escrever o valor 9 nos valores vazios dessa coluna.

# Nesta linha, estou preenchendo os valores ausentes na coluna "ESTCIVMAE"
# com o valor 9. O parâmetro "inplace=True" indica que a modificação deve ser
# feita diretamente no DataFrame 'sinasc', ou seja, ele será alterado
# permanentemente.

# O mesmo é feito na linha seguinte com a coluna "CONSULTAS".

sinasc['ESTCIVMAE'].fillna(9, inplace=True)
sinasc['CONSULTAS'].fillna(9, inplace=True)

# Por fim, seleciono as duas colunas para que seus valores sejam impressos e
# possamos ver as substituições realizadas

sinasc[['ESTCIVMAE', 'CONSULTAS']]

# 6) Substitua os valores faltantes da quantitativa (QTDFILVIVO) por zero.

# Apenas para fins de comparação, inicialmente verifico a quantidade de valores
# faltantes nessa variável

qtd_valores_faltantes = sinasc['QTDFILVIVO'].isnull().sum()

# Printando a variável

print("Quantidade de valores faltantes antes da substituição:",
      qtd_valores_faltantes)

# 6) Substitua os valores faltantes da quantitativa (QTDFILVIVO) por zero.

# Em seguida, substituo os valores faltantes da coluna "QTDFILVIVO", passando
# o parâmetro "inplace=True" para realizar a susbtituição diretamente no
# dataframe original

sinasc['QTDFILVIVO'].fillna(0, inplace=True)

# Imprimindo a coluna

sinasc['QTDFILVIVO']

# 6) Substitua os valores faltantes da quantitativa (QTDFILVIVO) por zero.

# Verificando novamente a quantidade de valores faltantes nessa variável, dessa
# vez após a substituição

qtd_valores_faltantes_2 = sinasc['QTDFILVIVO'].isnull().sum()

# Imprimindo a variável

print("Quantidade de valores faltantes após da substituição:",
      qtd_valores_faltantes_2)

# 7) Das restantes, decida que valores parecem mais adequados (um
# 'não preenchido' ou um valor 'mais provável' como no item anterior) e
# preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do
# cientista, e que estamos tomando decisões a todo o momento - não há
# necessariamente certo e errado aqui.

# Colunas_restantes 'LOCNASC', 'IDADEMAE', 'ESCMAE', 'GESTACAO', 'GRAVIDEZ'

# LOCNASC

sinasc['LOCNASC'].fillna("Não especificado", inplace=True)

# 7) Das restantes, decida que valores parecem mais adequados (um
# 'não preenchido' ou um valor 'mais provável' como no item anterior) e
# preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do
# cientista, e que estamos tomando decisões a todo o momento - não há
# necessariamente certo e errado aqui.

# IDADEMAE

mediana_idade_mae = sinasc['IDADEMAE'].median()

sinasc['IDADEMAE'].fillna(mediana_idade_mae, inplace=True)

# 7) Das restantes, decida que valores parecem mais adequados (um
# 'não preenchido' ou um valor 'mais provável' como no item anterior) e
# preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do
# cientista, e que estamos tomando decisões a todo o momento - não há
# necessariamente certo e errado aqui.

# ESCMAE

sinasc['ESCMAE'].fillna("Não especificado", inplace=True)

# 7) Das restantes, decida que valores parecem mais adequados (um
# 'não preenchido' ou um valor 'mais provável' como no item anterior) e
# preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do
# cientista, e que estamos tomando decisões a todo o momento - não há
# necessariamente certo e errado aqui.

# GESTACAO

# Neste código, estamos explicitamente convertendo os valores da coluna
# 'GESTACAO' para strings usando str(value) antes de aplicar a expressão
# regular.

import re

def convert_gestacao(value):
    value_str = str(value)
    match = re.match(r'(\d+)\s*a\s*(\d+)\s*semanas', value_str)

    if match:
        lower = int(match.group(1))
        upper = int(match.group(2))

        return (lower + upper) / 2
    elif 'mais' in value_str:
        return int(value_str.split()[0])
    else:
        return None

sinasc['GESTACAO'] = sinasc['GESTACAO'].apply(convert_gestacao)

mediana_gestacao = sinasc['GESTACAO'].median(skipna=True)

sinasc['GESTACAO'].fillna(mediana_gestacao, inplace=True)

print(sinasc['GESTACAO'])

# 7) Das restantes, decida que valores parecem mais adequados (um
# 'não preenchido' ou um valor 'mais provável' como no item anterior) e
# preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do
# cientista, e que estamos tomando decisões a todo o momento - não há
# necessariamente certo e errado aqui.

# GRAVIDEZ

# Inicio definindo um dicionário chamado "gravidez_mapping" que irá mapear os
# valores da coluna GRAVIDEZ para números correspondentes. Expandi o dicionário
# até a possibilidade de 5 gravidezes.

gravidez_mapping = {
    'Única': 1,
    'Dupla': 2,
    'Tripla': 3,
    'Quádrupla': 4,
    'Quíntupla': 5
}

# Utilizo o método map() para aplicar o mapeamento aos valores
# da coluna GRAVIDEZ

sinasc['GRAVIDEZ'] = sinasc['GRAVIDEZ'].map(gravidez_mapping)

# Calculo a mediana dos valores numéricos na coluna GRAVIDEZ, ignorando os
# valores ausentes através do parâmetro "skipna=True"

mediana_gravidez = sinasc['GRAVIDEZ'].median(skipna=True)

# Preenchi os valores ausentes na coluna GRAVIDEZ com a mediana calculada

sinasc['GRAVIDEZ'].fillna(mediana_gravidez, inplace=True)

# 7) Das restantes, decida que valores parecem mais adequados (um
# 'não preenchido' ou um valor 'mais provável' como no item anterior) e
# preencha. Justifique. Lembre-se de que tratamento de dados é trabalho do
# cientista, e que estamos tomando decisões a todo o momento - não há
# necessariamente certo e errado aqui.

# Imprimindo o dataframe para verificar as colunas modificadas

sinasc

# 8) O Apgar possui uma classificação indicando se o bebê passou por asfixia:

# Entre 8 e 10 está em uma faixa 'normal'.
# Entre 6 e 7, significa que o recém-nascido passou por 'asfixia leve'.
# Entre 4 e 5 significa 'asfixia moderada'.
# Entre 0 e 3 significa 'asfixia severa'.

# Crie uma categorização dessa variável com essa codificação e calcule as
# frequências dessa categorização.

# Criei um dicionário chamado "categorias", que mapeia as faixas de pontuação
# para as categorias correspondentes

categorias = {
    (8, 10): 'normal',
    (6, 7): 'asfixia leve',
    (4, 5): 'asfixia moderada',
    (0, 3): 'asfixia severa'
}

# Em seguida, a função categorize_apgar recebe uma pontuação de APGAR5 ("score")
# como entrada e itera sobre as faixas definidas no dicionário categorias para
# determinar em qual categoria a pontuação se encaixa

def categorize_apgar(score):
    for faixa, categoria in categorias.items():
        if faixa[0] <= score <= faixa[1]:
            return categoria

# Utilizo o método apply(), passando a função criada como parâmetro. Isso irá
# aplicar a função de categorização a cada valor na coluna APGAR5 e criar uma
# nova coluna "APGAR5_Categoria" com as categorias correspondentes

sinasc['APGAR5_Categoria'] = sinasc['APGAR5'].apply(categorize_apgar)

# Utilizando o método value_counts(), calculo as frequências das categorias na
# nova coluna

frequencias = sinasc['APGAR5_Categoria'].value_counts()

# Exibindo as frequências das categorias

print(frequencias)

# 8) O Apgar possui uma classificação indicando se o bebê passou por asfixia:

# Entre 8 e 10 está em uma faixa 'normal'.
# Entre 6 e 7, significa que o recém-nascido passou por 'asfixia leve'.
# Entre 4 e 5 significa 'asfixia moderada'.
# Entre 0 e 3 significa 'asfixia severa'.

# Crie uma categorização dessa variável com essa codificação e calcule as
# frequências dessa categorização.

# Imprimindo novamente o dataframe para verificar a nova coluna

sinasc

# 9) Renomeie as variáveis para que fiquem no snake case, ou seja, em letras
# minúsculas, com um underscore entre as palávras. Dica: repare que se você
# não quiser criar um dataframe novo, você vai precisar usar a opção
# inplace = True.

# Utilizei o método rename() para renomear todas as colunas no formato
# snake_case

sinasc.rename(columns={
    'ORIGEM': 'origem',
    'CODESTAB': 'cod_estab',
    'CODMUNNASC': 'cod_mun_nasc',
    'LOCNASC': 'loc_nasc',
    'IDADEMAE': 'idade_mae',
    'ESTCIVMAE': 'est_civ_mae',
    'ESCMAE': 'esc_mae',
    'CODOCUPMAE': 'cod_ocup_mae',
    'QTDFILVIVO': 'qtd_fil_vivo',
    'QTDFILMORT': 'qtd_fil_mort',
    'CODMUNRES': 'cod_mun_res',
    'GESTACAO': 'gestacao',
    'GRAVIDEZ': 'gravidez',
    'PARTO': 'parto',
    'CONSULTAS': 'consultas',
    'DTNASC': 'dt_nasc',
    'HORANASC': 'hora_nasc',
    'SEXO': 'sexo',
    'APGAR1': 'apgar1',
    'APGAR5': 'apgar5',
    'RACACOR': 'raca_cor',
    'PESO': 'peso',
    'IDANOMAL': 'id_anomal',
    'DTCADASTRO': 'dt_cadastro',
    'CODANOMAL': 'cod_anomal',
    'NUMEROLOTE': 'numero_lote',
    'VERSAOSIST': 'versao_sist',
    'DTRECEBIM': 'dt_recebim',
    'DIFDATA': 'dif_data',
    'DTRECORIGA': 'dt_recoriga',
    'NATURALMAE': 'natural_mae',
    'CODMUNNATU': 'cod_mun_natu',
    'CODUFNATU': 'cod_uf_natu',
    'ESCMAE2010': 'esc_mae2010',
    'SERIESCMAE': 'serie_esc_mae',
    'DTNASCMAE': 'dt_nasc_mae',
    'RACACORMAE': 'raca_cor_mae',
    'QTDGESTANT': 'qtd_gestant',
    'QTDPARTNOR': 'qtd_part_nor',
    'QTDPARTCES': 'qtd_part_ces',
    'IDADEPAI': 'idade_pai',
    'DTULTMENST': 'dt_ult_menst',
    'SEMAGESTAC': 'sem_agestac',
    'TPMETESTIM': 'tp_metestim',
    'CONSPRENAT': 'cons_prenat',
    'MESPRENAT': 'mes_prenat',
    'TPAPRESENT': 'tp_apresent',
    'STTRABPART': 'st_trab_part',
    'STCESPARTO': 'st_ces_parto',
    'TPNASCASSI': 'tp_nascassi',
    'TPFUNCRESP': 'tp_func_resp',
    'TPDOCRESP': 'tp_doc_resp',
    'DTDECLARAC': 'dt_declarac',
    'ESCMAEAGR1': 'esc_mae_agr1',
    'STDNEPIDEM': 'std_nepidem',
    'STDNNOVA': 'std_nnova',
    'CODPAISRES': 'cod_pais_res',
    'TPROBSON': 'tp_robson',
    'PARIDADE': 'paridade',
    'KOTELCHUCK': 'kotelchuck',
    'CONTADOR': 'contador',
    'munResStatus': 'mun_res_status',
    'munResTipo': 'mun_res_tipo',
    'munResNome': 'mun_res_nome',
    'munResUf': 'mun_res_uf',
    'munResLat': 'mun_res_lat',
    'munResLon': 'mun_res_lon',
    'munResAlt': 'mun_res_alt',
    'munResArea': 'mun_res_area',
    'APGAR5_Categoria': 'apgar5_categoria'
}, inplace=True)

# O parâmetr "inplace=True" faz com que as alterações sejam aplicadas
# diretamente ao dataframe sinasc

# Por fim, imprimo as colunas renomeadas para verificar o resultado

print(sinasc.columns)

# 9) Renomeie as variáveis para que fiquem no snake case, ou seja, em letras
# minúsculas, com um underscore entre as palávras. Dica: repare que se você
# não quiser criar um dataframe novo, você vai precisar usar a opção
# inplace = True.

# Imprimindo novamente o dataframe para verificar os novos nomes das colunas

sinasc